<?xml version="1.0"?>
<doc>
    <assembly>
        <name>OllamaFlow.Core</name>
    </assembly>
    <members>
        <member name="T:OllamaFlow.Core.Constants">
            <summary>
            Constants.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.Logo">
            <summary>
            Logo.
            See patorjk.com font Ogre.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.SettingsFile">
            <summary>
            Settings file.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.DatabaseFilename">
            <summary>
            Database filename.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.HtmlHomepage">
            <summary>
            Default HTML homepage.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.LogFilename">
            <summary>
            Log filename.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.LogDirectory">
            <summary>
            Log directory.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.BinaryContentType">
            <summary>
            Binary content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.JsonContentType">
            <summary>
            JSON content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.HtmlContentType">
            <summary>
            HTML content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.PngContentType">
            <summary>
            PNG content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.TextContentType">
            <summary>
            Text content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.FaviconFilename">
            <summary>
            Favicon filename.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.FaviconContentType">
            <summary>
            Favicon content type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.DefaultGUID">
            <summary>
            Default GUID.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.ForwardedForHeader">
            <summary>
            Forwarded for header, generally X-Forwarded-For.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.RequestIdHeader">
            <summary>
            Request ID header.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.BackendServerHeader">
            <summary>
            Backend server ID header.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.StickyServerHeader">
            <summary>
            Sticky server header.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.LabelHeader">
            <summary>
            Label header.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Constants.ExposeHeadersHeader">
            <summary>
            Expose headers header.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Database.DatabaseDriverBase">
            <summary>
            Base class for database driver.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Database.DatabaseDriverBase._Header">
            <summary>
            Logging header
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Database.DatabaseDriverBase._Logging">
            <summary>
            Logging module.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Database.DatabaseDriverBase._Serializer">
            <summary>
            Serializer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.DatabaseDriverBase.Frontend">
            <summary>
            Frontend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.DatabaseDriverBase.Backend">
            <summary>
            Backend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.DatabaseDriverBase.#ctor(SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer)">
            <summary>
            Base class for database driver.
            </summary>
            <param name="logging">Logging module.</param>
            <param name="serializer">Serializer.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.DatabaseDriverBase.InitializeRepository">
            <summary>
            Initialize the repository.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Database.Interfaces.IBackendMethods">
            <summary>
            Interface for backend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.Create(OllamaFlow.Core.Backend)">
            <summary>
            Create.
            </summary>
            <param name="obj">Record.</param>
            <returns>Record.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.CreateMany(System.Collections.Generic.List{OllamaFlow.Core.Backend})">
            <summary>
            Create multiple records.
            </summary>
            <param name="objs">Records.</param>
            <returns>Records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.ReadAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <summary>
            Read all records.
            </summary>
            <param name="order">Enumeration order.</param>
            <returns>Records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.ReadByIdentifiers(System.Collections.Generic.List{System.String})">
            <summary>
            Read objects by identifiers.
            </summary>
            <param name="ids">Identifiers.</param>
            <returns>Objects.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.Enumerate(OllamaFlow.Core.EnumerationRequest)">
            <summary>
            Enumerate objects.
            </summary>
            <param name="query">Enumeration query.</param>
            <returns>Enumeration result containing a page of objects.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.GetRecordCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <summary>
            Get the record count.  Optionally supply a continuation token to indicate that only records from that continuation token (identifier) should be counted.
            </summary>
            <param name="order">Enumeration order.</param>
            <param name="continuationToken">Continuation token.</param>
            <returns>Number of records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.Update(OllamaFlow.Core.Backend)">
            <summary>
            Update a record.
            </summary>
            <param name="obj">Record.</param>
            <returns>Record.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.DeleteByIdentifier(System.String)">
            <summary>
            Delete a record.
            </summary>
            <param name="id">Identifier.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.DeleteMany(System.Collections.Generic.List{System.String})">
            <summary>
            Delete records.
            </summary>
            <param name="ids">Identifiers.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.DeleteAll">
            <summary>
            Delete all records.  Do not use this if you are not absolutely sure you want to delete all records!
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.ExistsByGuidIdentifier(System.String)">
            <summary>
            Check if a record exists by identifier.
            </summary>
            <param name="id">Identifier.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IBackendMethods.IsLinked(System.String)">
            <summary>
            Check if a record is linked to another record.
            </summary>
            <param name="id">Identifier.</param>
            <returns>True if linked.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Database.Interfaces.IFrontendMethods">
            <summary>
            Interface for frontend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.Create(OllamaFlow.Core.Frontend)">
            <summary>
            Create.
            </summary>
            <param name="obj">Record.</param>
            <returns>Record.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.CreateMany(System.Collections.Generic.List{OllamaFlow.Core.Frontend})">
            <summary>
            Create multiple records.
            </summary>
            <param name="objs">Records.</param>
            <returns>Records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.ReadAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <summary>
            Read all records.
            </summary>
            <param name="order">Enumeration order.</param>
            <returns>Records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.ReadByIdentifiers(System.Collections.Generic.List{System.String})">
            <summary>
            Read objects by identifiers.
            </summary>
            <param name="ids">Identifiers.</param>
            <returns>Objects.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.Enumerate(OllamaFlow.Core.EnumerationRequest)">
            <summary>
            Enumerate objects.
            </summary>
            <param name="query">Enumeration query.</param>
            <returns>Enumeration result containing a page of objects.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.GetRecordCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <summary>
            Get the record count.  Optionally supply a continuation token to indicate that only records from that continuation token (identifier) should be counted.
            </summary>
            <param name="order">Enumeration order.</param>
            <param name="continuationToken">Continuation token.</param>
            <returns>Number of records.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.Update(OllamaFlow.Core.Frontend)">
            <summary>
            Update a record.
            </summary>
            <param name="obj">Record.</param>
            <returns>Record.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.DeleteByGuid(System.String)">
            <summary>
            Delete a record.
            </summary>
            <param name="id">Identifier.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.DeleteMany(System.Collections.Generic.List{System.String})">
            <summary>
            Delete records.
            </summary>
            <param name="ids">Identifiers.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.DeleteAll">
            <summary>
            Delete all records.  Do not use this if you are not absolutely sure you want to delete all records!
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Interfaces.IFrontendMethods.ExistsByIdentifier(System.String)">
            <summary>
            Check if a record exists by identifier.
            </summary>
            <param name="id">Identifier.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods">
            <summary>
            Backend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.Frontend">
            <summary>
            Frontend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.Backend">
            <summary>
            Backend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.#ctor(OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver)">
            <summary>
            Backend methods.
            </summary>
            <param name="repo">Database driver.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.Create(OllamaFlow.Core.Backend)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.CreateMany(System.Collections.Generic.List{OllamaFlow.Core.Backend})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.ReadAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.ReadByIdentifiers(System.Collections.Generic.List{System.String})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.Enumerate(OllamaFlow.Core.EnumerationRequest)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.GetRecordCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.Update(OllamaFlow.Core.Backend)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.DeleteByIdentifier(System.String)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.DeleteMany(System.Collections.Generic.List{System.String})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.DeleteAll">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.ExistsByGuidIdentifier(System.String)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.BackendMethods.IsLinked(System.String)">
            <inheritdoc />
        </member>
        <member name="T:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods">
            <summary>
            Frontend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.Frontend">
            <summary>
            Frontend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.Backend">
            <summary>
            Backend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.#ctor(OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver)">
            <summary>
            Frontend methods.
            </summary>
            <param name="repo">Database driver.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.Create(OllamaFlow.Core.Frontend)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.CreateMany(System.Collections.Generic.List{OllamaFlow.Core.Frontend})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.ReadAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.ReadByIdentifiers(System.Collections.Generic.List{System.String})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.Enumerate(OllamaFlow.Core.EnumerationRequest)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.GetRecordCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.Update(OllamaFlow.Core.Frontend)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.DeleteByGuid(System.String)">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.DeleteMany(System.Collections.Generic.List{System.String})">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.DeleteAll">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.Implementations.FrontendMethods.ExistsByIdentifier(System.String)">
            <inheritdoc />
        </member>
        <member name="T:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver">
            <summary>
            Sqlite database driver.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Filename">
            <summary>
            Sqlite database filename.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.MaxStatementLength">
            <summary>
            Maximum supported statement length.
            Default for Sqlite is 1,000,000,000 (see https://www.sqlite.org/limits.html).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.SelectBatchSize">
            <summary>
            Number of records to retrieve for object list retrieval.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.TimestampFormat">
            <summary>
            Timestamp format.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Frontend">
            <summary>
            Frontend methods.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Backend">
            <summary>
            Backend methods.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,System.String)">
            <summary>
            Sqlite database driver.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging.</param>
            <param name="serializer">Serializer.</param>
            <param name="filename">Database filename.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.InitializeRepository">
            <inheritdoc />
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Dispose">
            <summary>
            Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Dispose(System.Boolean)">
            <summary>
            Protected implementation of Dispose pattern.
            </summary>
            <param name="disposing">True if disposing managed resources.</param>
        </member>
        <member name="M:OllamaFlow.Core.Database.Sqlite.SqliteDatabaseDriver.Finalize">
            <summary>
            Finalizer for SqliteDatabaseDriver.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.ApiErrorEnum">
            <summary>
            API error codes.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.AuthenticationFailed">
            <summary>
            Authentication failed.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.AuthorizationFailed">
            <summary>
            Authorization failed.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.BadGateway">
            <summary>
            Bad gateway.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.BadRequest">
            <summary>
            Bad request.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.Conflict">
            <summary>
            Conflict.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.DeserializationError">
            <summary>
            DeserializationError.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.Inactive">
            <summary>
            Inactive.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.InternalError">
            <summary>
            Internal error.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.InvalidRange">
            <summary>
            Invalid range.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.InUse">
            <summary>
            In use.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.NotEmpty">
            <summary>
            Not empty.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.NotFound">
            <summary>
            Not found.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.SlowDown">
            <summary>
            Slow down.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.TokenExpired">
            <summary>
            Token expired.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.TooLarge">
            <summary>
            Request too large.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiErrorEnum.UnsupportedHttpVersion">
            <summary>
            Unsupported HTTP version.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.ApiFormatEnum">
            <summary>
            API format supported by backends.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiFormatEnum.Ollama">
            <summary>
            Ollama native API format.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiFormatEnum.OpenAI">
            <summary>
            OpenAI compatible API format.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.ApiFormatEnum.Unknown">
            <summary>
            Unknown API format.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.EnumerationOrderEnum">
            <summary>
            Enumeration order. 
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.EnumerationOrderEnum.CreatedAscending">
            <summary>
            Created ascending.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.EnumerationOrderEnum.CreatedDescending">
            <summary>
            Created descending.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.EnumerationOrderEnum.IdentifierAscending">
            <summary>
            Identifier ascending.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.EnumerationOrderEnum.IdentifierDescending">
            <summary>
            Identifier descending.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.LoadBalancingMode">
            <summary>
            Load balancing mode.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.LoadBalancingMode.Random">
            <summary>
            Random.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.LoadBalancingMode.RoundRobin">
            <summary>
            Round robin.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.MessageTypeEnum">
            <summary>
            Message type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.MessageTypeEnum.Telemetry">
            <summary>
            Telemetry.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Enums.RequestTypeEnum">
            <summary>
            Represents the different types of requests in a format-agnostic way.
            Used to categorize requests regardless of the source API format (Ollama, OpenAI, etc.).
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.Unknown">
            <summary>
            Unknown or unrecognized request type.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.Root">
            <summary>
            Root endpoint request.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.ValidateConnectivity">
            <summary>
            Validate connectivity request.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.GetFavicon">
            <summary>
            Get favicon endpoint request.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.ExistsFavicon">
            <summary>
            Exists favicon endpoint request.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaPullModel">
            <summary>
            Ollama API to pull a model from the registry.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaDeleteModel">
            <summary>
            Ollama API to delete a model.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaListModels">
            <summary>
            Ollama API to list available models.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaShowModelInformation">
            <summary>
            Ollama API to show detailed information about a model.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaListRunningModels">
            <summary>
            Ollama API to list currently running models.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaGenerateCompletion">
            <summary>
            Ollama API to generate a completion (non-chat).
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaGenerateChatCompletion">
            <summary>
            Ollama API to generate a chat completion.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OllamaGenerateEmbeddings">
            <summary>
            Ollama API to generate embeddings for a single input.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OpenAIGenerateCompletion">
            <summary>
            OpenAI API to generate a completion (non-chat).
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OpenAIGenerateChatCompletion">
            <summary>
            OpenAI API to generate a chat completion.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.OpenAIGenerateEmbeddings">
            <summary>
            OpenAI API to generate embeddings for a single input.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetFrontends">
            <summary>
            Admin API request to list frontends.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetFrontend">
            <summary>
            Admin API request to get a specific frontend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminExistsFrontend">
            <summary>
            Admin API request to check existence of a specific frontend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminCreateFrontend">
            <summary>
            Admin API request to create a frontend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminUpdateFrontend">
            <summary>
            Admin API request to update a frontend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminDeleteFrontend">
            <summary>
            Admin API request to delete a frontend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetBackends">
            <summary>
            Admin API request to get backends.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetBackend">
            <summary>
            Admin API request to get a specific backend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminExistsBackend">
            <summary>
            Admin API request to check existence of a specific backend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminCreateBackend">
            <summary>
            Admin API request to create a backend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminUpdateBackend">
            <summary>
            Admin API request to update a backend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminDeleteBackend">
            <summary>
            Admin API request to delete a backend.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetBackendsHealth">
            <summary>
            Admin API request to get health status of all backends.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Enums.RequestTypeEnum.AdminGetBackendHealth">
            <summary>
            Admin API request to get health status of a specific backend.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Handlers.AdminApiHandler">
            <summary>
            Administrative API handler for managing frontends, backends, and sessions.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Administrative API handler for managing frontends, backends, and sessions.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging.</param>
            <param name="serializer">Serializer.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.IsAuthenticated(WatsonWebserver.Core.HttpContextBase)">
            <summary>
            Check if the request is authenticated with a valid bearer token.
            </summary>
            <param name="ctx">HTTP context.</param>
            <returns>True if authenticated, false otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetFrontendsRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get all frontends.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetFrontendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get a specific frontend by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when frontend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.ExistsFrontendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Check if a frontend exists by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.DeleteFrontendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Delete a frontend by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when frontend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.CreateFrontendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Create a new frontend.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.ArgumentException">Thrown when frontend with specified identifier already exists.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.UpdateFrontendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Update an existing frontend.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when frontend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetBackendsRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get all backends.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetBackendsHealthRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get health status of all backends.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetBackendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get a specific backend by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when backend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.ExistsBackendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Check if a backend exists by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.GetBackendHealthRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Get health status of a specific backend by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when backend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.DeleteBackendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Delete a backend by identifier.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when backend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.CreateBackendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Create a new backend.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.ArgumentException">Thrown when backend with specified identifier already exists.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.UpdateBackendRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Update an existing backend.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
            <exception cref="T:System.UnauthorizedAccessException">Thrown when request is not authenticated.</exception>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">Thrown when backend with specified identifier is not found.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.AdminApiHandler.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Handlers.HandlerContext">
            <summary>
            Handler context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Handlers.HandlerContext.AdminApi">
            <summary>
            Admin API handler.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Handlers.HandlerContext.StaticRoute">
            <summary>
            Static route handler.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Handler context.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging module.</param>
            <param name="serializer">Serializer.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.AddAdminApi">
            <summary>
            Add admin API handler.
            </summary>
            <returns>Handler context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.AddStaticRoute">
            <summary>
            Add static route handler/
            </summary>
            <returns>Handler context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.HandlerContext.Initialize">
            <summary>
            Initialize handlers.
            </summary>
            <returns>Handler context.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Handlers.StaticRouteHandler">
            <summary>
            Handler for static routes like root, favicon, and other simple HTTP responses.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,System.Threading.CancellationTokenSource)">
            <summary>
            Handler for static routes like root, favicon, and other simple HTTP responses.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.GetRootRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Handle GET request to root path.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.HeadRootRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Handle HEAD request to root path.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.GetFaviconRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Handle GET request to favicon.ico.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.HeadFaviconRoute(WatsonWebserver.Core.HttpContextBase,System.Threading.CancellationToken)">
            <summary>
            Handle HEAD request to favicon.ico.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Handlers.StaticRouteHandler.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Helpers.HttpMethodHelper">
            <summary>
            HTTP method helper.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Helpers.HttpMethodHelper.ToHttpMethod(System.String)">
            <summary>
            Convert an HTTP method string to an HttpMethod.
            </summary>
            <param name="str">String.</param>
            <returns>HttpMethod.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Helpers.HttpMethodHelper.FromHttpMethod(System.Net.Http.HttpMethod)">
            <summary>
            Convert an HTTP method to a string.
            </summary>
            <param name="method">HttpMethod.</param>
            <returns>String.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Helpers.RequestTypeHelper">
            <summary>
            Request type helper.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Helpers.RequestTypeHelper.IsEmbeddingsRequest(OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Boolean indicating if the request is an embeddings request.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Helpers.RequestTypeHelper.IsCompletionsRequest(OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Boolean indicating if the request is a chat completion request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.ApiErrorResponse">
            <summary>
            API error response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.ApiErrorResponse.Error">
            <summary>
            Error.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.ApiErrorResponse.Message">
            <summary>
            Human-readable message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.ApiErrorResponse.StatusCode">
            <summary>
            HTTP status code.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.ApiErrorResponse.Context">
            <summary>
            Additional contextual information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.ApiErrorResponse.Description">
            <summary>
            Description.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.ApiErrorResponse.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.ApiErrorResponse.#ctor(OllamaFlow.Core.Enums.ApiErrorEnum,System.Object,System.String)">
            <summary>
            Instantiate.
            </summary>
            <param name="error">Error code.</param>
            <param name="context">Context.</param>
            <param name="description">Description.</param>
            
        </member>
        <member name="T:OllamaFlow.Core.Backend">
            <summary>
            Origin server.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Backend.Serializer">
            <summary>
            Serializer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Identifier">
            <summary>
            Unique identifier for this origin server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Name">
            <summary>
            Name for this origin server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Hostname">
            <summary>
            Hostname.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Port">
            <summary>
            TCP port.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Ssl">
            <summary>
            Enable or disable SSL.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.UrlPrefix">
            <summary>
            URL prefix.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.UnhealthyThreshold">
            <summary>
            Number of consecutive failed health checks before marking a server as unhealthy.
            Default is 2.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.HealthyThreshold">
            <summary>
            Number of consecutive successful health checks before marking a server as healthy.
            Default is 2.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.HealthCheckMethod">
            <summary>
            HTTP method to use when performing a healthcheck.
            Default is GET.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.HealthCheckUrl">
            <summary>
            URL to use when performing a healthcheck.
            Default is /.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.MaxParallelRequests">
            <summary>
            Maximum number of parallel requests to this backend.
            Default is 4.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.RateLimitRequestsThreshold">
            <summary>
            Threshold at which 429 rate limit responses are sent.
            Default is 10.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.LogRequestFull">
            <summary>
            Boolean indicating if the full request should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.LogRequestBody">
            <summary>
            Boolean indicating if the request body should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.LogResponseBody">
            <summary>
            Boolean indicating if the response body should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.ApiFormat">
            <summary>
            API format supported by this backend.
            Default is Ollama.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.PinnedEmbeddingsPropertiesString">
            <summary>
            String containing JSON-serialized pinned properties, which will be applied to every embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Labels">
            <summary>
            List of string labels for the backend; these are used in load-balancing decisions.  
            When a request is received with a label, only backends with matching labels will be considered.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.LabelsString">
            <summary>
            String containing JSON-serialized labels for the backend; these are used in load-balancing decisions.  
            When a request is received with a label, only backends with matching labels will be considered.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.PinnedEmbeddingsProperties">
            <summary>
            Dictionary containing pinned properties, which will be applied to every embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.PinnedCompletionsPropertiesString">
            <summary>
            String containing JSON-serialized pinned properties, which will be applied to every completions request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.PinnedCompletionsProperties">
            <summary>
            Dictionary containing pinned properties, which will be applied to every completions request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.AllowEmbeddings">
            <summary>
            Boolean indicating if embeddings requests are allowed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.AllowCompletions">
            <summary>
            Boolean indicating if completions requests are allowed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Active">
            <summary>
            Boolean indicating if the object is active or not.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.CreatedUtc">
            <summary>
            Creation timestamp, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.LastUpdateUtc">
            <summary>
            Last update timestamp, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.HealthySinceUtc">
            <summary>
            Timestamp at which the backend was seen as healthy, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.UnhealthySinceUtc">
            <summary>
            Timestamp at which the backend was seen as unhealthy, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Uptime">
            <summary>
            Uptime for the backend.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.Downtime">
            <summary>
            Downtime for the backend.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.ActiveRequests">
            <summary>
            Number of active requests.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Backend.IsSticky">
            <summary>
            Boolean indicating whether or not the backend was chosen due to stickiness.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Backend.#ctor">
            <summary>
            Backend server.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.EnumerationRequest">
            <summary>
            Object used to request enumeration.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationRequest.Ordering">
            <summary>
            Order by.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationRequest.MaxResults">
            <summary>
            Maximum number of results to retrieve.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationRequest.Skip">
            <summary>
            The number of records to skip.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationRequest.ContinuationToken">
            <summary>
            Continuation token.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.EnumerationRequest.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.EnumerationResult`1">
            <summary>
            Object returned as the result of an enumeration.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.Success">
            <summary>
            Indicates if the statistics operation was successful.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.Timestamp">
            <summary>
            Start and end timestamps.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.MaxResults">
            <summary>
            Maximum number of results to retrieve.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.ContinuationToken">
            <summary>
            Continuation token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.EndOfResults">
            <summary>
            Boolean indicating end of results.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.TotalRecords">
            <summary>
            Total number of records.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.RecordsRemaining">
            <summary>
            Number of candidate records remaining in the enumeration.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.EnumerationResult`1.Objects">
            <summary>
            Objects.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.EnumerationResult`1.#ctor">
            <summary>
            Instantiates the object.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Frontend">
            <summary>
            API endpoint.
            </summary>
        </member>
        <member name="F:OllamaFlow.Core.Frontend.Serializer">
            <summary>
            Serializer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.Identifier">
            <summary>
            Unique identifier for this API endpoint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.Name">
            <summary>
            Name for this API endpoint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.Hostname">
            <summary>
            Hostname associated with this frontend.
            Use * to specify that this frontend is a catch-all.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.TimeoutMs">
            <summary>
            Number of milliseconds to wait before considering the request to be timed out.
            Default is 60 seconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.LoadBalancing">
            <summary>
            Load-balancing mode.
            Default is RoundRobin.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.BlockHttp10">
            <summary>
            True to terminate HTTP/1.0 requests.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.MaxRequestBodySize">
            <summary>
            Maximum request body size.  Default is 512MB.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.Backends">
            <summary>
            Ollama backend server identifiers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.BackendsString">
            <summary>
            String containing JSON-serialized list of backend identifiers.
            Used by the database layer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.RequiredModels">
            <summary>
            List of models that should be present on each mapped backend Ollama server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.RequiredModelsString">
            <summary>
            String containing JSON-serialized list of required models.
            Used by the database layer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.LogRequestFull">
            <summary>
            Boolean indicating if the full request should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.LogRequestBody">
            <summary>
            Boolean indicating if the request body should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.LogResponseBody">
            <summary>
            Boolean indicating if the response body should be logged.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.UseStickySessions">
            <summary>
            Boolean indicating whether sticky sessions should be used for this frontend.
            When enabled, clients will be routed to the same backend for subsequent requests.
            Default is false.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.StickySessionExpirationMs">
            <summary>
            Duration in milliseconds for how long a sticky session should remain active.
            Default is 1800000 milliseconds (30 minutes).
            Minimum is 10000 milliseconds (10 seconds).
            Maximum is 86400000 milliseconds (24 hours).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.PinnedEmbeddingsPropertiesString">
            <summary>
            Do not use this property unless the backends mapped to this frontend use the same API format as what will be sent to this frontend.
            String containing JSON-serialized pinned properties, which will be applied to every embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.PinnedEmbeddingsProperties">
            <summary>
            Do not use this property unless the backends mapped to this frontend use the same API format as what will be sent to this frontend.
            Dictionary containing pinned properties, which will be applied to every embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.PinnedCompletionsPropertiesString">
            <summary>
            Do not use this property unless the backends mapped to this frontend use the same API format as what will be sent to this frontend.
            String containing JSON-serialized pinned properties, which will be applied to every completions request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.PinnedCompletionsProperties">
            <summary>
            Do not use this property unless the backends mapped to this frontend use the same API format as what will be sent to this frontend.
            Dictionary containing pinned properties, which will be applied to every completions request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.AllowEmbeddings">
            <summary>
            Boolean indicating if embeddings requests are allowed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.AllowCompletions">
            <summary>
            Boolean indicating if completions requests are allowed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.AllowRetries">
            <summary>
            Allow OllamaFlow to retry failed requests.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.Active">
            <summary>
            Boolean indicating if the object is active or not.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.CreatedUtc">
            <summary>
            Creation timestamp, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Frontend.LastUpdateUtc">
            <summary>
            Last update timestamp, in UTC time.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Frontend.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.MessageEnvelope">
            <summary>
            Message envelope.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.MessageEnvelope.Type">
            <summary>
            Type of message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.MessageEnvelope.MessageGuid">
            <summary>
            Message GUID.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.MessageEnvelope.Data">
            <summary>
            Data.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.MessageEnvelope.Metadata">
            <summary>
            Metadata.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.MessageEnvelope.#ctor">
            <summary>
            Message envelope.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics">
            <summary>
            Performance metrics for chat completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.PromptTokens">
            <summary>
            Number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.CompletionTokens">
            <summary>
            Number of tokens generated.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.TotalTokens">
            <summary>
            Total number of tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.PromptTokensPerSecond">
            <summary>
            Prompt evaluation rate (tokens/second).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.GenerationTokensPerSecond">
            <summary>
            Generation rate (tokens/second).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.TotalDurationMs">
            <summary>
            Total response time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.LoadDurationMs">
            <summary>
            Model load time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.PromptEvalDurationMs">
            <summary>
            Prompt evaluation time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.GenerationDurationMs">
            <summary>
            Generation time in milliseconds.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.FromResult(OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult)">
            <summary>
            Creates metrics from a chat completion result.
            </summary>
            <param name="result">The chat completion result.</param>
            <returns>Metrics object or null if insufficient data.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatCompletionMetrics.#ctor">
            <summary>
            Ollama chat completion metrics.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaChatMessage">
            <summary>
            Ollama chat message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatMessage.Role">
            <summary>
            Role of the message sender (required).
            Valid values: "system", "user", "assistant", "tool"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatMessage.Content">
            <summary>
            Content of the message (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatMessage.Images">
            <summary>
            Base64-encoded images for multimodal models (optional).
            Only valid for user messages.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaChatMessage.ToolCalls">
            <summary>
            Tool calls made by the assistant (optional).
            Only valid for assistant messages.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatMessage.#ctor">
            <summary>
            Ollama chat message.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaChatResponseMessage">
            <summary>
            Extension of OllamaChatMessage for response-specific properties.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatResponseMessage.IsToolCallResponse">
            <summary>
            Tool calls made by the assistant (if any).
            Inherited from OllamaChatMessage.
            </summary>
            <summary>
            Checks if this is a tool call response.
            </summary>
            <returns>True if the message contains tool calls.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatResponseMessage.GetFirstToolCall">
            <summary>
            Gets the first tool call if available.
            </summary>
            <returns>First tool call or null if none.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaChatResponseMessage.#ctor">
            <summary>
            Ollama chat response message.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext">
            <summary>
            Helper class for managing completion context across requests.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.Data">
            <summary>
            The context data.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.Model">
            <summary>
            The model this context is for.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.LastUpdated">
            <summary>
            When this context was last updated.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.FromResult(OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult)">
            <summary>
            Creates a context from a completion result.
            </summary>
            <param name="result">The completion result.</param>
            <returns>Context object or null if no context available.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.IsValidForModel(System.String)">
            <summary>
            Checks if this context is valid for a given model.
            </summary>
            <param name="modelName">The model name to check.</param>
            <returns>True if context is valid for the model.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.GetAge">
            <summary>
            Gets the age of this context.
            </summary>
            <returns>Time since last update.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionContext.#ctor">
            <summary>
            Ollama completion context.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics">
            <summary>
            Performance metrics for completion generation.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.PromptTokens">
            <summary>
            Number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.CompletionTokens">
            <summary>
            Number of tokens generated.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.TotalTokens">
            <summary>
            Total number of tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.ContextSize">
            <summary>
            Size of the context maintained.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.PromptTokensPerSecond">
            <summary>
            Prompt evaluation rate (tokens/second).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.GenerationTokensPerSecond">
            <summary>
            Generation rate (tokens/second).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.TotalDurationMs">
            <summary>
            Total response time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.LoadDurationMs">
            <summary>
            Model load time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.PromptEvalDurationMs">
            <summary>
            Prompt evaluation time in milliseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.GenerationDurationMs">
            <summary>
            Generation time in milliseconds.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.FromResult(OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult)">
            <summary>
            Creates metrics from a completion result.
            </summary>
            <param name="result">The completion result.</param>
            <returns>Metrics object or null if insufficient data.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionMetrics.#ctor">
            <summary>
            Ollama completion metrics.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions">
            <summary>
            Ollama completion options for model parameters.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.Seed">
            <summary>
            Random seed for generation (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumPredict">
            <summary>
            Number of tokens to generate (optional, default: infinite).
            -1 = infinite, -2 = fill context
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumGpu">
            <summary>
            Number of layers to offload to GPU (optional).
            0 = no GPU, -1 = all layers
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.Temperature">
            <summary>
            Temperature for sampling (optional, default: 0.8).
            Range: 0.0 to 2.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.TopK">
            <summary>
            Top-k sampling parameter (optional, default: 40).
            Range: 0 to 100
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.TopP">
            <summary>
            Top-p sampling parameter (optional, default: 0.9).
            Range: 0.0 to 1.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.MinP">
            <summary>
            Min-p sampling parameter (optional, default: 0.0).
            Range: 0.0 to 1.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.TfsZ">
            <summary>
            Tail free sampling parameter (optional, default: 1.0).
            Range: 0.0 to 1.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.TypicalP">
            <summary>
            Typical sampling parameter (optional, default: 1.0).
            Range: 0.0 to 1.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.RepeatPenalty">
            <summary>
            Repeat penalty (optional, default: 1.1).
            Range: 0.0 to 2.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.RepeatLastN">
            <summary>
            Last n tokens to consider for repeat penalty (optional, default: 64).
            Range: 0 to context size
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.PresencePenalty">
            <summary>
            Presence penalty (optional, default: 0.0).
            Range: -2.0 to 2.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.FrequencyPenalty">
            <summary>
            Frequency penalty (optional, default: 0.0).
            Range: -2.0 to 2.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.Mirostat">
            <summary>
            Mirostat sampling mode (0/1/2) (optional, default: 0).
            0 = disabled, 1 = Mirostat v1, 2 = Mirostat v2
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.MirostatTau">
            <summary>
            Mirostat target entropy tau (optional, default: 5.0).
            Range: 0.0 to 10.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.MirostatEta">
            <summary>
            Mirostat learning rate eta (optional, default: 0.1).
            Range: 0.0 to 1.0
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.PenalizeNewline">
            <summary>
            Penalize newline tokens (optional, default: true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.Stop">
            <summary>
            Stop sequences for generation (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.Numa">
            <summary>
            Enable NUMA support (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumCtx">
            <summary>
            Context size (optional, default: 2048).
            Range: 128 to 1048576
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumBatch">
            <summary>
            Batch size for prompt evaluation (optional, default: 512).
            Range: 1 to context size
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumThread">
            <summary>
            Number of threads to use (optional).
            Range: 1 to 128
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.NumKeep">
            <summary>
            Number of tokens to keep from initial prompt (optional, default: 4).
            Range: 0 to context size
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.UseMlock">
            <summary>
            Use memory locking (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.UseMmap">
            <summary>
            Use memory mapping (optional, default: true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.VocabOnly">
            <summary>
            Vocabulary only mode (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.LowVram">
            <summary>
            Low VRAM mode (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.F16Kv">
            <summary>
            F16 key-value storage (optional, default: true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.MainGpu">
            <summary>
            Main GPU index (optional).
            Range: 0 to number of GPUs - 1
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.LogitsAll">
            <summary>
            Logits all mode (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaCompletionOptions.#ctor">
            <summary>
            Ollama completion options.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaDeleteModelRequest">
            <summary>
            Ollama delete model request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaDeleteModelRequest.Model">
            <summary>
            Name of the model to delete (required).
            No one knows why Ollama chose to use the 'name' property here instead of 'model', which is used by the other APIs.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaDeleteModelRequest.#ctor">
            <summary>
            Ollama delete model request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsInputConverter">
            <summary>
            Custom JSON converter for flexible input handling (string or array of strings).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsInputConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Read.
            </summary>
            <param name="reader">Reader.</param>
            <param name="typeToConvert">Type to convert.</param>
            <param name="options">Options.</param>
            <returns>Object.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsInputConverter.Write(System.Text.Json.Utf8JsonWriter,System.Object,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Write.
            </summary>
            <param name="writer">Writer.</param>
            <param name="value">Value.</param>
            <param name="options">Options.</param>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions">
            <summary>
            Ollama embeddings options.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.NumThread">
            <summary>
            Number of threads to use (optional).
            Range: 1 to 128
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.NumCtx">
            <summary>
            Context size (optional).
            Range: 128 to 1048576
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.NumGpu">
            <summary>
            Number of layers to offload to GPU (optional).
            0 = no GPU, -1 = all layers
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.MainGpu">
            <summary>
            Main GPU index (optional).
            Range: 0 to number of GPUs - 1
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.LowVram">
            <summary>
            Low VRAM mode (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.F16Kv">
            <summary>
            F16 key-value storage (optional, default: true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.Numa">
            <summary>
            Enable NUMA support (optional, default: false).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.UseMmap">
            <summary>
            Use memory mapping (optional, default: true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.UseMlock">
            <summary>
            Use memory locking (optional, default: false).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOptions.#ctor">
            <summary>
            Ollama embeddings options.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOutputConverter">
            <summary>
            Custom JSON converter for flexible embeddings handling (single array or array of arrays).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOutputConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Read.
            </summary>
            <param name="reader">Reader.</param>
            <param name="typeToConvert">Type to convert.</param>
            <param name="options">Options.</param>
            <returns>Object.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaEmbeddingsOutputConverter.Write(System.Text.Json.Utf8JsonWriter,System.Object,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Write.
            </summary>
            <param name="writer">Writer.</param>
            <param name="value">Value.</param>
            <param name="options">Options.</param>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk">
            <summary>
            Ollama generate chat completion chunk (single chunk from streaming response).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.Message">
            <summary>
            The partial message generated by the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.Done">
            <summary>
            Whether the response is complete.
            False for intermediate chunks, true for the final chunk.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.DoneReason">
            <summary>
            Reason why the response is done.
            Examples: "stop", "length", "function_call"
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.TotalDuration">
            <summary>
            Total duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.LoadDuration">
            <summary>
            Model load duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.PromptEvalDuration">
            <summary>
            Prompt evaluation duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.EvalCount">
            <summary>
            Number of tokens generated in the response.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.EvalDuration">
            <summary>
            Response generation duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionChunk.#ctor">
            <summary>
            Ollama generate chat completion chunk.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest">
            <summary>
            Ollama generate chat completion request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Model">
            <summary>
            Model name to use for chat completion (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Messages">
            <summary>
            Messages for the chat (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Options">
            <summary>
            Additional model parameters (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Format">
            <summary>
            Format to return the response in. Currently only "json" is supported (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Template">
            <summary>
            The full prompt template (overrides what is defined in the Modelfile) (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Stream">
            <summary>
            Enable streaming of generated text (optional, defaults to true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.KeepAlive">
            <summary>
            How long to keep the model loaded in memory (optional).
            Examples: "5m", "10m", "1h", "never"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.Tools">
            <summary>
            Tools/functions available for the model to use (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionRequest.#ctor">
            <summary>
            Ollama generate chat completion request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult">
            <summary>
            Ollama generate chat completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.Message">
            <summary>
            The message generated by the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.Done">
            <summary>
            Whether the response is complete.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.DoneReason">
            <summary>
            Reason why the response is done.
            Examples: "stop", "length", "function_call"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.TotalDuration">
            <summary>
            Total duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.LoadDuration">
            <summary>
            Model load duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.PromptEvalDuration">
            <summary>
            Prompt evaluation duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.EvalCount">
            <summary>
            Number of tokens generated in the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.EvalDuration">
            <summary>
            Response generation duration in nanoseconds.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.GetPromptTokensPerSecond">
            <summary>
            Gets the prompt evaluation rate in tokens per second.
            </summary>
            <returns>Tokens per second for prompt evaluation, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.GetGenerationTokensPerSecond">
            <summary>
            Gets the response generation rate in tokens per second.
            </summary>
            <returns>Tokens per second for generation, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.GetTotalDurationMilliseconds">
            <summary>
            Gets the total response time in milliseconds.
            </summary>
            <returns>Total duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.GetLoadDurationMilliseconds">
            <summary>
            Gets the model load time in milliseconds.
            </summary>
            <returns>Load duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.HasToolCalls">
            <summary>
            Checks if the response contains tool calls.
            </summary>
            <returns>True if the message contains tool calls.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.GetTotalTokenCount">
            <summary>
            Gets the total number of tokens (prompt + generated).
            </summary>
            <returns>Total token count, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionResult.#ctor">
            <summary>
            Ollama generate chat completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionStreamingResult">
            <summary>
            Ollama generate chat completion streaming result wrapper.
            This wrapper is returned immediately and contains an async enumerable stream of chunks.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionStreamingResult.Chunks">
            <summary>
            The async enumerable stream of chat completion chunks.
            Yields OllamaGenerateChatCompletionChunk objects as they arrive from the server.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateChatCompletionStreamingResult.#ctor">
            <summary>
            Ollama generate chat completion streaming result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk">
            <summary>
            Ollama generate completion chunk (single chunk from streaming response).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.Response">
            <summary>
            The partial generated text response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.Done">
            <summary>
            Whether the response is complete.
            False for intermediate chunks, true for the final chunk.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.Context">
            <summary>
            Context for maintaining conversation state.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.TotalDuration">
            <summary>
            Total duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.LoadDuration">
            <summary>
            Model load duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.PromptEvalDuration">
            <summary>
            Prompt evaluation duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.EvalCount">
            <summary>
            Number of tokens generated in the response.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.EvalDuration">
            <summary>
            Response generation duration in nanoseconds.
            Only present in the final chunk (when done=true).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionChunk.#ctor">
            <summary>
            Ollama generate completion chunk.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest">
            <summary>
            Ollama generate completion request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Model">
            <summary>
            Model name to use for generation (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Prompt">
            <summary>
            The prompt to generate a response for (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Options">
            <summary>
            Additional model parameters (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.System">
            <summary>
            System message to use (overrides what is defined in the Modelfile) (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Template">
            <summary>
            The full prompt or prompt template (overrides what is defined in the Modelfile) (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Context">
            <summary>
            The context from a previous request, used to keep a conversation going (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Stream">
            <summary>
            Enable streaming of generated text (optional, defaults to true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Raw">
            <summary>
            If false, the response will not include the prompt (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Format">
            <summary>
            Format to return the response in. Currently only "json" is supported (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.Images">
            <summary>
            Base64-encoded images for multimodal models (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.KeepAlive">
            <summary>
            How long to keep the model loaded in memory (optional).
            Examples: "5m", "10m", "1h", "never"
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionRequest.#ctor">
            <summary>
            Ollama generate completion request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult">
            <summary>
            Ollama generate completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.Response">
            <summary>
            The generated text response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.Context">
            <summary>
            Context for maintaining conversation state.
            Can be passed in the next request to continue the conversation.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.TotalDuration">
            <summary>
            Total duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.LoadDuration">
            <summary>
            Model load duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.PromptEvalDuration">
            <summary>
            Prompt evaluation duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.EvalCount">
            <summary>
            Number of tokens generated in the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.EvalDuration">
            <summary>
            Response generation duration in nanoseconds.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetPromptTokensPerSecond">
            <summary>
            Gets the prompt evaluation rate in tokens per second.
            </summary>
            <returns>Tokens per second for prompt evaluation, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetGenerationTokensPerSecond">
            <summary>
            Gets the response generation rate in tokens per second.
            </summary>
            <returns>Tokens per second for generation, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetTotalDurationMilliseconds">
            <summary>
            Gets the total response time in milliseconds.
            </summary>
            <returns>Total duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetLoadDurationMilliseconds">
            <summary>
            Gets the model load time in milliseconds.
            </summary>
            <returns>Load duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetPromptEvalDurationMilliseconds">
            <summary>
            Gets the prompt evaluation time in milliseconds.
            </summary>
            <returns>Prompt evaluation duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetEvalDurationMilliseconds">
            <summary>
            Gets the generation time in milliseconds.
            </summary>
            <returns>Generation duration in milliseconds, or null if unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetTotalTokenCount">
            <summary>
            Gets the total number of tokens (prompt + generated).
            </summary>
            <returns>Total token count, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.HasContext">
            <summary>
            Checks if context is available for continuing the conversation.
            </summary>
            <returns>True if context is available.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.GetContextSize">
            <summary>
            Gets the size of the context in tokens.
            </summary>
            <returns>Context size or 0 if no context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionResult.#ctor">
            <summary>
            Ollama generate completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionStreamingResult">
            <summary>
            Ollama generate completion streaming result wrapper.
            This wrapper is returned immediately and contains an async enumerable stream of chunks.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionStreamingResult.Chunks">
            <summary>
            The async enumerable stream of completion chunks.
            Yields OllamaGenerateCompletionChunk objects as they arrive from the server.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateCompletionStreamingResult.#ctor">
            <summary>
            Ollama generate completion streaming result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest">
            <summary>
            Ollama generate embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.Model">
            <summary>
            Model name to use for generating embeddings (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.Input">
            <summary>
            Input text(s) to generate embeddings for (required).
            Can be a single string or an array of strings.
            Use SetInput() or SetInputs() to set values, and GetInputs() to retrieve as array.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.Options">
            <summary>
            Options for generating embeddings (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.KeepAlive">
            <summary>
            How long to keep the model loaded in memory (optional).
            Examples: "5m", "10m", "1h", "never"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.Truncate">
            <summary>
            Truncate inputs that exceed the model's context window (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.SetInput(System.String)">
            <summary>
            Sets a single input string.
            </summary>
            <param name="input">The input string.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.SetInputs(System.Collections.Generic.List{System.String})">
            <summary>
            Sets multiple input strings.
            </summary>
            <param name="inputs">The array of input strings.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.GetInput">
            <summary>
            Gets the input as a single string.
            Throws an exception if the input is a list.
            </summary>
            <returns>The input string.</returns>
            <exception cref="T:System.InvalidOperationException">Thrown when input is a list instead of a single string.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.GetInputs">
            <summary>
            Gets the input as an array of strings.
            If input is a single string, returns an array with one element.
            </summary>
            <returns>Array of input strings.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.IsSingleInput">
            <summary>
            Checks if the input is a single string.
            </summary>
            <returns>True if input is a single string, false otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsRequest.#ctor">
            <summary>
            Ollama generate embeddings request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult">
            <summary>
            Ollama generate embeddings result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.Model">
            <summary>
            The model that generated the embeddings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.Embeddings">
            <summary>
            Generated embedding(s).
            Can be a single array of floats or an array of arrays of floats.
            Use GetEmbedding() for single result or GetEmbeddings() for multiple results.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.TotalDuration">
            <summary>
            Total duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.LoadDuration">
            <summary>
            Model load duration in nanoseconds.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.PromptEvalCount">
            <summary>
            Prompt evaluation count.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.GetEmbedding">
            <summary>
            Gets a single embedding array.
            Throws if the result contains multiple embeddings.
            </summary>
            <returns>Single embedding array.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.GetEmbeddings">
            <summary>
            Gets all embeddings as a list of arrays.
            If result is a single embedding, returns a list with one element.
            </summary>
            <returns>List of embedding arrays.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.IsSingleEmbedding">
            <summary>
            Checks if the result contains a single embedding.
            </summary>
            <returns>True if single embedding, false if multiple.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.IsMultiEmbeddings">
            <summary>
            Checks if the result contains multiple embeddings.
            </summary>
            <returns>True if multiple embeddings, false if single.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.GetEmbeddingCount">
            <summary>
            Gets the number of embeddings in the result.
            </summary>
            <returns>Number of embeddings.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.GetEmbeddingDimension">
            <summary>
            Gets the dimension (length) of the embeddings.
            All embeddings in the result should have the same dimension.
            </summary>
            <returns>Dimension of embeddings, or null if no embeddings.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaGenerateEmbeddingsResult.#ctor">
            <summary>
            Ollama generate embeddings result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult">
            <summary>
            Ollama list local models result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.Models">
            <summary>
            List of models available locally.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetModelCount">
            <summary>
            Gets the total number of models.
            </summary>
            <returns>Number of local models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetTotalSizeBytes">
            <summary>
            Gets the total size of all models in bytes.
            </summary>
            <returns>Total size in bytes.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetFormattedTotalSize">
            <summary>
            Gets the total size of all models in a human-readable format.
            </summary>
            <returns>Formatted total size string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.FindModel(System.String,System.Boolean)">
            <summary>
            Finds a model by name.
            </summary>
            <param name="modelName">The model name to search for.</param>
            <param name="exactMatch">Whether to require exact match or allow partial/case-insensitive match.</param>
            <returns>The matching model or null if not found.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetModelsByFamily(System.String)">
            <summary>
            Gets all models from a specific family.
            </summary>
            <param name="family">The model family (e.g., "llama", "mistral").</param>
            <returns>List of models from the specified family.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetQuantizedModels">
            <summary>
            Gets all quantized models.
            </summary>
            <returns>List of quantized models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetModelsSortedBySize(System.Boolean)">
            <summary>
            Gets models sorted by size.
            </summary>
            <param name="ascending">True for smallest first, false for largest first.</param>
            <returns>Sorted list of models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetModelsSortedByDate(System.Boolean)">
            <summary>
            Gets models sorted by modification date.
            </summary>
            <param name="mostRecentFirst">True for most recent first.</param>
            <returns>Sorted list of models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetModelsModifiedSince(System.DateTime)">
            <summary>
            Gets models that were modified within a specific time period.
            </summary>
            <param name="since">The start date/time.</param>
            <returns>List of models modified since the specified time.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GroupModelsByBaseName">
            <summary>
            Groups models by their base name (without tag).
            </summary>
            <returns>Dictionary grouping models by base name.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.GetStatistics">
            <summary>
            Gets statistics about the local models.
            </summary>
            <returns>Model statistics.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult.#ctor">
            <summary>
            Ollama list local models result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult">
            <summary>
            Ollama list running models result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.Models">
            <summary>
            List of models currently loaded in memory.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetRunningModelCount">
            <summary>
            Gets the total number of running models.
            </summary>
            <returns>Number of running models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetTotalVRAMUsage">
            <summary>
            Gets the total VRAM usage of all running models in bytes.
            </summary>
            <returns>Total VRAM usage in bytes.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetFormattedTotalVRAMUsage">
            <summary>
            Gets the total VRAM usage formatted as a string.
            </summary>
            <returns>Formatted VRAM usage.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetTotalRAMUsage">
            <summary>
            Gets the total system RAM usage of all running models in bytes.
            </summary>
            <returns>Total RAM usage in bytes.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetFormattedTotalRAMUsage">
            <summary>
            Gets the total system RAM usage formatted as a string.
            </summary>
            <returns>Formatted RAM usage.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetTotalMemoryUsage">
            <summary>
            Gets the total memory usage (VRAM + RAM) of all running models.
            </summary>
            <returns>Total memory usage in bytes.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetFormattedTotalMemoryUsage">
            <summary>
            Gets the total memory usage formatted as a string.
            </summary>
            <returns>Formatted total memory usage.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.FindRunningModel(System.String)">
            <summary>
            Finds a running model by name.
            </summary>
            <param name="modelName">The model name to search for.</param>
            <returns>The running model or null if not found.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.IsModelRunning(System.String)">
            <summary>
            Checks if a specific model is currently running.
            </summary>
            <param name="modelName">The model name to check.</param>
            <returns>True if the model is running.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetModelsExpiringWithin(System.TimeSpan)">
            <summary>
            Gets models that will expire within a specified timeframe.
            </summary>
            <param name="within">Timespan to check for expiration.</param>
            <returns>List of models expiring within the timeframe.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetNextExpiringModel">
            <summary>
            Gets the model that will expire next.
            </summary>
            <returns>Model with the earliest expiration or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetModelsSortedByMemoryUsage(System.Boolean)">
            <summary>
            Gets models sorted by memory usage.
            </summary>
            <param name="ascending">True for smallest first, false for largest first.</param>
            <returns>Sorted list of running models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetModelsSortedByVRAMUsage(System.Boolean)">
            <summary>
            Gets models sorted by VRAM usage.
            </summary>
            <param name="ascending">True for smallest first, false for largest first.</param>
            <returns>Sorted list of running models.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GroupByFamily">
            <summary>
            Groups running models by family.
            </summary>
            <returns>Dictionary of models grouped by family.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.GetStatistics">
            <summary>
            Gets memory usage statistics for running models.
            </summary>
            <returns>Memory usage statistics.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult.#ctor">
            <summary>
            Ollama list running models result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaLocalModel">
            <summary>
            Ollama local model information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.Name">
            <summary>
            Model name including tag (e.g., "llama2:latest").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.Digest">
            <summary>
            Model digest/hash.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.Size">
            <summary>
            Model size in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.ModifiedAt">
            <summary>
            When the model was last modified.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.Details">
            <summary>
            Model details including format, family, parameter size, and quantization.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetBaseName">
            <summary>
            Gets the model's base name without tag.
            </summary>
            <returns>Base model name.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetTag">
            <summary>
            Gets the model's tag.
            </summary>
            <returns>Model tag or "latest" if no tag specified.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetFormattedSize">
            <summary>
            Gets the formatted size of the model.
            </summary>
            <returns>Human-readable size string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetShortDigest">
            <summary>
            Gets a short digest identifier.
            </summary>
            <returns>First 12 characters of the digest.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetAge">
            <summary>
            Gets the age of the model since last modification.
            </summary>
            <returns>Time since last modification.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.GetFormattedAge">
            <summary>
            Gets a formatted age string.
            </summary>
            <returns>Human-readable age string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.MatchesPattern(System.String)">
            <summary>
            Checks if this model matches a given pattern.
            </summary>
            <param name="pattern">Pattern to match (supports wildcards).</param>
            <returns>True if the model name matches the pattern.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaLocalModel.#ctor">
            <summary>
            Ollama local model.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaModelDetails">
            <summary>
            Ollama model details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.ParentModel">
            <summary>
            Parent model this was created from.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.Format">
            <summary>
            Model format (e.g., "gguf").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.Family">
            <summary>
            Model family (e.g., "llama", "mistral").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.Families">
            <summary>
            Model families/architectures.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.ParameterSize">
            <summary>
            Parameter size (e.g., "7B", "13B", "70B").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.QuantizationLevel">
            <summary>
            Quantization level (e.g., "Q4_0", "Q4_K_M", "Q8_0").
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.GetParameterSizeInBillions">
            <summary>
            Gets the estimated model size in billions of parameters.
            </summary>
            <returns>Number of billions of parameters, or null if cannot parse.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.GetQuantizationBits">
            <summary>
            Gets the quantization bits from the quantization level.
            </summary>
            <returns>Number of bits used for quantization, or null if cannot determine.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.IsQuantized">
            <summary>
            Checks if this is a quantized model.
            </summary>
            <returns>True if the model is quantized.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.BelongsToFamily(System.String)">
            <summary>
            Checks if this model belongs to a specific family.
            </summary>
            <param name="familyName">The family name to check.</param>
            <returns>True if the model belongs to the specified family.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelDetails.#ctor">
            <summary>
            Ollama model details.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter">
            <summary>
            Helper class for interpreting model information.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.#ctor(OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult)">
            <summary>
            Creates a new model info interpreter.
            </summary>
            <param name="result">The model info result to interpret.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.EstimateVRAMRequirement">
            <summary>
            Gets the estimated VRAM requirement in GB.
            </summary>
            <returns>Estimated VRAM in GB, or null if cannot estimate.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.GetContextLength">
            <summary>
            Gets the context length from parameters if available.
            </summary>
            <returns>Context length or null if not found.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.GetTemperature">
            <summary>
            Gets the temperature setting from parameters if available.
            </summary>
            <returns>Temperature value or null if not found.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.MeetsRequirements(System.Nullable{System.Double},System.Nullable{System.Int32})">
            <summary>
            Determines if this model is suitable for a given use case.
            </summary>
            <param name="requiredVRAM">Required VRAM in GB.</param>
            <param name="requiredContext">Required context length.</param>
            <returns>True if the model meets the requirements.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelInfoInterpreter.GetSummary">
            <summary>
            Gets a summary of the model's key characteristics.
            </summary>
            <returns>Summary string.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics">
            <summary>
            Statistics about local models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.TotalModels">
            <summary>
            Total number of models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.TotalSizeBytes">
            <summary>
            Total size of all models in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.TotalSizeFormatted">
            <summary>
            Total size formatted as string.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.AverageSizeBytes">
            <summary>
            Average model size in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.AverageSizeFormatted">
            <summary>
            Average model size formatted as string.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.LargestModel">
            <summary>
            Largest model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.SmallestModel">
            <summary>
            Smallest model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.NewestModel">
            <summary>
            Most recently modified model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.OldestModel">
            <summary>
            Oldest modified model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.ModelsByFamily">
            <summary>
            Count of models by family.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.ModelsByQuantization">
            <summary>
            Count of models by quantization level.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.ModelsByParameterSize">
            <summary>
            Count of models by parameter size.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.#ctor(OllamaFlow.Core.Models.Ollama.OllamaListLocalModelsResult)">
            <summary>
            Creates statistics from a list result.
            </summary>
            <param name="result">The list models result.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaModelStatistics.GetSummary">
            <summary>
            Gets a summary of the statistics.
            </summary>
            <returns>Summary string.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest">
            <summary>
            Ollama pull model request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Model">
            <summary>
            Model name to pull (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Name">
            <summary>
            Model name to pull (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Insecure">
            <summary>
            Allow insecure connections to the registry (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Stream">
            <summary>
            Enable streaming of pull progress (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Username">
            <summary>
            Username for registry authentication (optional).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.Password">
            <summary>
            Password for registry authentication (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelRequest.#ctor">
            <summary>
            Ollama pull model request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage">
            <summary>
            Ollama pull model result message for streaming updates during model download.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.Status">
            <summary>
            Current status of the pull operation.
            Examples: "pulling manifest", "downloading", "verifying sha256 digest", "writing manifest", "removing any unused layers", "success"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.Digest">
            <summary>
            Digest of the layer being downloaded.
            Format: "sha256:hash"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.Total">
            <summary>
            Total size of the current layer in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.Completed">
            <summary>
            Number of bytes completed for the current layer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.Error">
            <summary>
            Error message if the pull operation failed.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetProgressPercentage">
            <summary>
            Gets the download progress as a percentage.
            </summary>
            <returns>Progress percentage (0-100), or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetRemainingBytes">
            <summary>
            Gets the remaining bytes to download.
            </summary>
            <returns>Remaining bytes, or null if data unavailable.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetFormattedTotalSize">
            <summary>
            Formats the total size in a human-readable format.
            </summary>
            <returns>Formatted size string (e.g., "1.5 GB").</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetFormattedCompletedSize">
            <summary>
            Formats the completed size in a human-readable format.
            </summary>
            <returns>Formatted size string (e.g., "750 MB").</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetFormattedProgress">
            <summary>
            Gets a formatted progress string.
            </summary>
            <returns>Progress string (e.g., "750 MB / 1.5 GB (50%)").</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.IsDownloadProgress">
            <summary>
            Checks if this is a download progress message.
            </summary>
            <returns>True if this message contains download progress information.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.IsComplete">
            <summary>
            Checks if the operation is complete.
            </summary>
            <returns>True if the status indicates completion.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.HasError">
            <summary>
            Checks if the operation has failed.
            </summary>
            <returns>True if an error occurred.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.IsStatusMessage">
            <summary>
            Checks if this is a status-only message (no download progress).
            </summary>
            <returns>True if this is a status message without progress data.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.GetLayerId">
            <summary>
            Gets the layer identifier from the digest.
            </summary>
            <returns>Short form of the digest (first 12 characters of hash), or null if no digest.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.EstimateTimeRemaining(System.Double)">
            <summary>
            Estimates time remaining based on a given download rate.
            </summary>
            <param name="bytesPerSecond">Current download rate in bytes per second.</param>
            <returns>Estimated time remaining, or null if cannot be calculated.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
            <param name="bytes">Number of bytes.</param>
            <returns>Formatted string (e.g., "1.5 GB").</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage.#ctor">
            <summary>
            Ollama pull model result message.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker">
            <summary>
            Helper class for tracking pull operation progress across multiple messages.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.TotalBytes">
            <summary>
            Total bytes to download across all layers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.CompletedBytes">
            <summary>
            Total bytes completed across all layers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.CurrentStatus">
            <summary>
            Current status message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.CurrentLayer">
            <summary>
            Current layer being downloaded.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.LayersCompleted">
            <summary>
            Number of layers completed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.OverallProgress">
            <summary>
            Gets the overall progress percentage.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.DownloadRate">
            <summary>
            Gets the current download rate in bytes per second.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.ElapsedTime">
            <summary>
            Gets the elapsed time since the pull started.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.Update(OllamaFlow.Core.Models.Ollama.OllamaPullModelResultMessage)">
            <summary>
            Updates the tracker with a new message.
            </summary>
            <param name="message">The pull result message.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.EstimateTimeRemaining">
            <summary>
            Estimates time remaining for the entire pull operation.
            </summary>
            <returns>Estimated time remaining, or null if cannot be calculated.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.GetSummary">
            <summary>
            Gets a formatted summary of the pull progress.
            </summary>
            <returns>Summary string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.FormatTimeSpan(System.TimeSpan)">
            <summary>
            Formats a timespan into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaPullProgressTracker.#ctor">
            <summary>
            Creates a new pull progress tracker.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaRunningModel">
            <summary>
            Ollama running model information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.Name">
            <summary>
            Model name including tag.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.Digest">
            <summary>
            Model digest/hash.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.Size">
            <summary>
            Total memory size in bytes (RAM + VRAM).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.SizeVRAM">
            <summary>
            VRAM usage in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.ExpiresAt">
            <summary>
            When the model expires from memory.
            ISO 8601 format string.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.Details">
            <summary>
            Model details including format, family, parameter size, and quantization.
            Reusing the existing OllamaModelDetails class.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetRAMUsage">
            <summary>
            Gets the system RAM usage (total size minus VRAM).
            </summary>
            <returns>RAM usage in bytes.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetFormattedSize">
            <summary>
            Gets the formatted total memory size.
            </summary>
            <returns>Human-readable size string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetFormattedVRAMSize">
            <summary>
            Gets the formatted VRAM usage.
            </summary>
            <returns>Human-readable VRAM size string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetFormattedRAMSize">
            <summary>
            Gets the formatted RAM usage.
            </summary>
            <returns>Human-readable RAM size string.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetVRAMPercentage">
            <summary>
            Gets the percentage of memory in VRAM vs RAM.
            </summary>
            <returns>Percentage of memory in VRAM (0-100).</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetTimeUntilExpiration">
            <summary>
            Gets time until the model expires from memory.
            </summary>
            <returns>Time remaining or null if no expiration set.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetFormattedTimeUntilExpiration">
            <summary>
            Gets formatted time until expiration.
            </summary>
            <returns>Human-readable time remaining.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.HasExpired">
            <summary>
            Checks if the model has expired.
            </summary>
            <returns>True if the model has expired.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetEstimatedExpiration">
            <summary>
            Gets estimated expiration time based on expires_at field.
            </summary>
            <returns>Estimated expiration DateTime or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetBaseName">
            <summary>
            Gets the model's base name without tag.
            </summary>
            <returns>Base model name.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetTag">
            <summary>
            Gets the model's tag.
            </summary>
            <returns>Model tag or "latest" if no tag specified.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.GetMemoryUsageSummary">
            <summary>
            Gets a memory usage summary.
            </summary>
            <returns>Summary string of memory usage.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModel.#ctor">
            <summary>
            Ollama running model.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics">
            <summary>
            Statistics about running models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalRunningModels">
            <summary>
            Total number of running models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalMemoryBytes">
            <summary>
            Total memory usage in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalMemoryFormatted">
            <summary>
            Total memory usage formatted.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalVRAMBytes">
            <summary>
            Total VRAM usage in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalVRAMFormatted">
            <summary>
            Total VRAM usage formatted.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalRAMBytes">
            <summary>
            Total RAM usage in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.TotalRAMFormatted">
            <summary>
            Total RAM usage formatted.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.AverageMemoryBytes">
            <summary>
            Average memory per model in bytes.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.AverageMemoryFormatted">
            <summary>
            Average memory per model formatted.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.LargestModel">
            <summary>
            Model using the most memory.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.SmallestModel">
            <summary>
            Model using the least memory.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.NextToExpire">
            <summary>
            Model expiring soonest.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.ModelsUsingVRAM">
            <summary>
            Number of models with VRAM allocation.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.AverageVRAMPercentage">
            <summary>
            Average VRAM percentage across models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.ModelsByFamily">
            <summary>
            Count of running models by family.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.#ctor(OllamaFlow.Core.Models.Ollama.OllamaListRunningModelsResult)">
            <summary>
            Creates statistics from running models result.
            </summary>
            <param name="result">The running models result.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.FormatBytes(System.Int64)">
            <summary>
            Formats bytes into human-readable format.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaRunningModelStatistics.GetSummary">
            <summary>
            Gets a summary of the statistics.
            </summary>
            <returns>Summary string.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoRequest">
            <summary>
            Ollama show model information request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoRequest.Model">
            <summary>
            Name of the model to show (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoRequest.Verbose">
            <summary>
            Include verbose information about the model (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoRequest.#ctor">
            <summary>
            Ollama show model information request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult">
            <summary>
            Ollama show model information result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.License">
            <summary>
            Model license information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.Modelfile">
            <summary>
            Model file content (when verbose is true).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.Parameters">
            <summary>
            Model parameters configuration.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.Template">
            <summary>
            Template used for prompts.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.System">
            <summary>
            System message/prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.Details">
            <summary>
            Model details including format, family, families, parameter size, and quantization level.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.Messages">
            <summary>
            Messages/examples used in the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.ModelInfo">
            <summary>
            Model information including general metadata.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.ModifiedAt">
            <summary>
            Modified timestamp.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.IsVerboseResponse">
            <summary>
            Checks if this is a verbose response with full details.
            </summary>
            <returns>True if verbose information is included.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.HasSystemPrompt">
            <summary>
            Checks if the model has a system prompt configured.
            </summary>
            <returns>True if system prompt is present.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.HasExampleMessages">
            <summary>
            Checks if the model has example messages.
            </summary>
            <returns>True if example messages are present.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.GetParameterSize">
            <summary>
            Gets the model's parameter size from details if available.
            </summary>
            <returns>Parameter size string (e.g., "7B", "13B") or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.GetQuantizationLevel">
            <summary>
            Gets the model's quantization level from details if available.
            </summary>
            <returns>Quantization level string (e.g., "Q4_0", "Q8_0") or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.ParseParameters">
            <summary>
            Parses the parameters string into a dictionary.
            </summary>
            <returns>Dictionary of parameter key-value pairs.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaShowModelInfoResult.#ctor">
            <summary>
            Ollama show model information result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult">
            <summary>
            Ollama streaming chat completion result.
            Used for intermediate streaming responses.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult.Message">
            <summary>
            The partial message generated by the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult.Done">
            <summary>
            Whether this is the final chunk in the stream.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaStreamingChatCompletionResult.#ctor">
            <summary>
            Ollama streaming chat completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult">
            <summary>
            Ollama streaming completion result.
            Used for intermediate streaming responses.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult.Model">
            <summary>
            The model that generated the response.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult.CreatedAt">
            <summary>
            The timestamp of when the response was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult.Response">
            <summary>
            The partial response text.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult.Done">
            <summary>
            Whether this is the final chunk in the stream.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaStreamingCompletionResult.#ctor">
            <summary>
            Ollama streaming completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaTool">
            <summary>
            Ollama tool definition.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaTool.Type">
            <summary>
            Type of tool (required).
            Currently only "function" is supported.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaTool.Function">
            <summary>
            Function definition (required when type is "function").
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaTool.#ctor">
            <summary>
            Ollama tool.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaToolCall">
            <summary>
            Ollama tool call made by the assistant.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolCall.Function">
            <summary>
            Function that was called (required).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaToolCall.#ctor">
            <summary>
            Ollama tool call.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaToolCallFunction">
            <summary>
            Ollama tool call function details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolCallFunction.Name">
            <summary>
            Name of the function that was called (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolCallFunction.Arguments">
            <summary>
            Arguments passed to the function as a JSON string (required).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaToolCallFunction.#ctor">
            <summary>
            Ollama tool call function.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaToolFunction">
            <summary>
            Ollama tool function definition.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolFunction.Name">
            <summary>
            Name of the function (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolFunction.Description">
            <summary>
            Description of what the function does (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolFunction.Parameters">
            <summary>
            Parameters the function accepts, described as a JSON Schema object (required).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaToolFunction.#ctor">
            <summary>
            Ollama tool function.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.Ollama.OllamaToolParameters">
            <summary>
            Ollama tool parameters schema.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolParameters.Type">
            <summary>
            Type of the parameters object (required).
            Should typically be "object".
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolParameters.Properties">
            <summary>
            Properties of the parameters object (required).
            Each property is a JSON Schema definition.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.Ollama.OllamaToolParameters.Required">
            <summary>
            List of required property names (optional).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.Ollama.OllamaToolParameters.#ctor">
            <summary>
            Ollama tool parameters.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice">
            <summary>
            OpenAI chat completion choice.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.Index">
            <summary>
            Index of this choice.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.Message">
            <summary>
            Chat message generated by the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.Delta">
            <summary>
            Delta message for streaming responses.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.Logprobs">
            <summary>
            Log probabilities information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.FinishReason">
            <summary>
            Reason the generation stopped.
            Possible values: "stop", "length", "tool_calls", "content_filter", "function_call"
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIChatChoice.#ctor">
            <summary>
            OpenAI chat choice.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk">
            <summary>
            OpenAI chat completion chunk (single chunk from streaming response).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Id">
            <summary>
            Unique identifier for the chat completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Object">
            <summary>
            Object type (always "chat.completion.chunk").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.SystemFingerprint">
            <summary>
            System fingerprint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Choices">
            <summary>
            List of chat completion choices with delta updates.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.Usage">
            <summary>
            Usage statistics for the completion.
            Only present in the final chunk when stream_options.include_usage is true.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIChatCompletionChunk.#ctor">
            <summary>
            OpenAI chat completion chunk.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent">
            <summary>
            OpenAI chat logprob content.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent.Token">
            <summary>
            The token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent.Logprob">
            <summary>
            Log probability of this token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent.Bytes">
            <summary>
            UTF-8 byte representation of the token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent.TopLogprobs">
            <summary>
            Top alternative tokens and their log probabilities.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobContent.#ctor">
            <summary>
            OpenAI chat logprob content.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobs">
            <summary>
            OpenAI chat logprobs data.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobs.Content">
            <summary>
            Log probability information for each content token.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIChatLogprobs.#ctor">
            <summary>
            OpenAI chat logprobs.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage">
            <summary>
            OpenAI chat message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.Role">
            <summary>
            Role of the message sender (required).
            Valid values: "system", "user", "assistant", "tool"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.Content">
            <summary>
            Content of the message.
            Can be a string or an array of content parts for multimodal input.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.Name">
            <summary>
            Name of the author of this message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.ToolCalls">
            <summary>
            Tool calls made by the assistant.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.ToolCallId">
            <summary>
            Tool call ID this message is responding to.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIChatMessage.#ctor">
            <summary>
            OpenAI chat message.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice">
            <summary>
            OpenAI completion choice.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice.Text">
            <summary>
            Generated text.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice.Index">
            <summary>
            Index of this choice.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice.Logprobs">
            <summary>
            Log probabilities information.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice.FinishReason">
            <summary>
            Reason the generation stopped.
            Possible values: "stop", "length"
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChoice.#ctor">
            <summary>
            OpenAI completion choice.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk">
            <summary>
            OpenAI completion chunk (single chunk from streaming response).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.Id">
            <summary>
            Unique identifier for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.Object">
            <summary>
            Object type (always "text_completion").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.SystemFingerprint">
            <summary>
            System fingerprint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.Choices">
            <summary>
            List of completion choices.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAICompletionChunk.#ctor">
            <summary>
            OpenAI completion chunk.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails">
            <summary>
            OpenAI completion tokens details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails.ReasoningTokens">
            <summary>
            Number of reasoning tokens generated.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails.AudioTokens">
            <summary>
            Number of audio tokens generated.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails.AcceptedPredictionTokens">
            <summary>
            Number of tokens that were accepted.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails.RejectedPredictionTokens">
            <summary>
            Number of tokens that were rejected.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAICompletionTokensDetails.#ctor">
            <summary>
            OpenAI completion tokens details.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIEmbedding">
            <summary>
            OpenAI embedding data.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIEmbedding.Object">
            <summary>
            Object type (always "embedding").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIEmbedding.Index">
            <summary>
            Index of this embedding in the input array.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIEmbedding.Embedding">
            <summary>
            The embedding vector.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIEmbedding.#ctor">
            <summary>
            OpenAI embedding.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIEmbeddingsInputConverter">
            <summary>
            Converter for flexible embedding input (string or array).
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIEmbeddingUsage">
            <summary>
            OpenAI embedding usage statistics.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIEmbeddingUsage.PromptTokens">
            <summary>
            Number of tokens in the input.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIEmbeddingUsage.TotalTokens">
            <summary>
            Total number of tokens used.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIEmbeddingUsage.#ctor">
            <summary>
            OpenAI embedding usage.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIError">
            <summary>
            OpenAI error message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIError.Error">
            <summary>
            Error details.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIError.#ctor">
            <summary>
            OpenAI error message.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails">
            <summary>
            OpenAI error details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails.Message">
            <summary>
            Message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails.Type">
            <summary>
            Type.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails.Parameters">
            <summary>
            Parameters.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails.Code">
            <summary>
            Code.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIErrorDetails.#ctor">
            <summary>
            OpenAI error details.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest">
            <summary>
            OpenAI generate chat completion request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Model">
            <summary>
            ID of the model to use (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Messages">
            <summary>
            Messages for the chat conversation (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.ResponseFormat">
            <summary>
            Response format specification.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.MaxTokens">
            <summary>
            The maximum number of tokens to generate.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Temperature">
            <summary>
            Temperature for sampling (0-2).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.TopP">
            <summary>
            Nucleus sampling parameter (0-1).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.N">
            <summary>
            Number of chat completions to generate for each input message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Stream">
            <summary>
            Whether to stream partial progress.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Stop">
            <summary>
            Up to 4 sequences where the API will stop generating further tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.PresencePenalty">
            <summary>
            Presence penalty (-2.0 to 2.0).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.FrequencyPenalty">
            <summary>
            Frequency penalty (-2.0 to 2.0).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.LogitBias">
            <summary>
            Modify the likelihood of specified tokens appearing in the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Logprobs">
            <summary>
            Include the log probabilities on the logprobs most likely tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.TopLogprobs">
            <summary>
            Number of most likely tokens to return at each token position.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.User">
            <summary>
            A unique identifier representing your end-user.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Tools">
            <summary>
            Functions/tools the model may call.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.ToolChoice">
            <summary>
            Controls which (if any) tool is called by the model.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.ParallelToolCalls">
            <summary>
            Whether to enable parallel function calling.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.Seed">
            <summary>
            Random seed for deterministic generation.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionRequest.#ctor">
            <summary>
            OpenAI generate chat completion request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult">
            <summary>
            OpenAI generate chat completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Id">
            <summary>
            Unique identifier for the chat completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Object">
            <summary>
            Object type (always "chat.completion").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.SystemFingerprint">
            <summary>
            System fingerprint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Choices">
            <summary>
            List of chat completion choices.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.Usage">
            <summary>
            Usage statistics for the completion.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.GetCreatedDateTime">
            <summary>
            Gets the created timestamp as DateTime.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.GetAssistantMessage">
            <summary>
            Gets the primary message from the assistant.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.HasToolCalls">
            <summary>
            Checks if any choice contains tool calls.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.GetAllToolCalls">
            <summary>
            Gets all tool calls from all choices.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionResult.#ctor">
            <summary>
            OpenAI generate chat completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionStreamingResult">
            <summary>
            OpenAI generate chat completion streaming result wrapper.
            This wrapper is returned immediately and contains an async enumerable stream of chunks.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionStreamingResult.Chunks">
            <summary>
            The async enumerable stream of chat completion chunks.
            Yields OpenAIChatCompletionChunk objects as they arrive from the server.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateChatCompletionStreamingResult.#ctor">
            <summary>
            OpenAI generate chat completion streaming result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest">
            <summary>
            OpenAI generate completion request.
            Note: The completions endpoint is legacy. Use chat completions for new applications.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Model">
            <summary>
            ID of the model to use (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Prompt">
            <summary>
            The prompt(s) to generate completions for (required).
            Can be a string or an array of strings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Suffix">
            <summary>
            The suffix that comes after a completion of inserted text.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.MaxTokens">
            <summary>
            The maximum number of tokens to generate.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Temperature">
            <summary>
            Temperature for sampling (0-2).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.TopP">
            <summary>
            Nucleus sampling parameter (0-1).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.N">
            <summary>
            Number of completions to generate for each prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Stream">
            <summary>
            Whether to stream partial progress.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Logprobs">
            <summary>
            Include the log probabilities on the logprobs most likely tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Echo">
            <summary>
            Echo back the prompt in addition to the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Stop">
            <summary>
            Up to 4 sequences where the API will stop generating further tokens.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.PresencePenalty">
            <summary>
            Presence penalty (-2.0 to 2.0).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.FrequencyPenalty">
            <summary>
            Frequency penalty (-2.0 to 2.0).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.BestOf">
            <summary>
            Generates best_of completions server-side and returns the best.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.LogitBias">
            <summary>
            Modify the likelihood of specified tokens appearing in the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.User">
            <summary>
            A unique identifier representing your end-user.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.Seed">
            <summary>
            Random seed for deterministic generation.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.GetPrompt">
            <summary>
            Gets the prompt as a single string.
            Throws an exception if the prompt is a list.
            </summary>
            <returns>The prompt string.</returns>
            <exception cref="T:System.InvalidOperationException">Thrown when prompt is a list instead of a single string.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.GetPrompts">
            <summary>
            Gets the prompt as an array of strings.
            If prompt is a single string, returns an array with one element.
            </summary>
            <returns>Array of prompt strings.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.SetPrompt(System.String)">
            <summary>
            Sets a single prompt string.
            </summary>
            <param name="prompt">The prompt string.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.SetPrompts(System.Collections.Generic.List{System.String})">
            <summary>
            Sets multiple prompts from a List.
            </summary>
            <param name="prompts">The list of prompt strings.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.SetPrompts(System.String[])">
            <summary>
            Sets multiple prompts from an array.
            </summary>
            <param name="prompts">The array of prompt strings.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.IsSinglePrompt">
            <summary>
            Checks if the prompt is a single string.
            </summary>
            <returns>True if prompt is a single string, false otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionRequest.#ctor">
            <summary>
            OpenAI generate completion request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult">
            <summary>
            OpenAI generate completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Id">
            <summary>
            Unique identifier for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Object">
            <summary>
            Object type (always "text_completion").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.SystemFingerprint">
            <summary>
            System fingerprint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Choices">
            <summary>
            List of completion choices.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.Usage">
            <summary>
            Usage statistics for the completion.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.GetCreatedDateTime">
            <summary>
            Gets the created timestamp as DateTime.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.GetCompletionText">
            <summary>
            Gets the primary completion text.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.HasTruncatedChoices">
            <summary>
            Checks if any choice was truncated due to length.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionResult.#ctor">
            <summary>
            OpenAI generate completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionStreamingResult">
            <summary>
            OpenAI generate completion streaming result wrapper.
            This wrapper is returned immediately and contains an async enumerable stream of chunks.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionStreamingResult.Chunks">
            <summary>
            The async enumerable stream of completion chunks.
            Yields OpenAICompletionChunk objects as they arrive from the server.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateCompletionStreamingResult.#ctor">
            <summary>
            OpenAI generate completion streaming result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest">
            <summary>
            OpenAI generate embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.Model">
            <summary>
            ID of the model to use (required).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.Input">
            <summary>
            Input text to embed (required).
            Can be a string or an array of strings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.EncodingFormat">
            <summary>
            The format to return the embeddings in.
            Can be either "float" or "base64".
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.Dimensions">
            <summary>
            The number of dimensions the resulting output embeddings should have.
            Only supported in some models.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.User">
            <summary>
            A unique identifier representing your end-user.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.SetInput(System.String)">
            <summary>
            Sets a single input string.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.SetInputs(System.Collections.Generic.List{System.String})">
            <summary>
            Sets multiple input strings.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsRequest.#ctor">
            <summary>
            OpenAI generate embeddings request.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult">
            <summary>
            OpenAI generate embeddings result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.Object">
            <summary>
            Object type (always "list").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.Data">
            <summary>
            List of embedding objects.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.Model">
            <summary>
            Model used to generate embeddings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.Usage">
            <summary>
            Usage statistics.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.GetEmbedding">
            <summary>
            Gets a single embedding array.
            Throws if the result contains multiple embeddings.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.GetEmbeddings">
            <summary>
            Gets all embeddings as a list of arrays.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.GetEmbeddingsArray">
            <summary>
            Gets all embeddings as a jagged array.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.IsSingleEmbedding">
            <summary>
            Checks if the result contains a single embedding.
            </summary>
            <returns>True if single embedding, false if multiple.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.IsMultiEmbeddings">
            <summary>
            Checks if the result contains multiple embeddings.
            </summary>
            <returns>True if multiple embeddings, false if single.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.GetEmbeddingCount">
            <summary>
            Gets the number of embeddings in the result.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.GetEmbeddingDimension">
            <summary>
            Gets the dimension of the embeddings.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIGenerateEmbeddingsResult.#ctor">
            <summary>
            OpenAI generate embeddings result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs">
            <summary>
            OpenAI logprobs data.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs.Tokens">
            <summary>
            List of token strings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs.TokenLogprobs">
            <summary>
            Log probabilities for each token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs.TopLogprobs">
            <summary>
            Top log probabilities for each token position.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs.TextOffset">
            <summary>
            Text offset for each token.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAILogprobs.#ctor">
            <summary>
            OpenAI logprobs.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIPromptInputConverter">
            <summary>
            Converter for flexible prompt input (string or array).
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIPromptTokensDetails">
            <summary>
            OpenAI prompt tokens details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIPromptTokensDetails.CachedTokens">
            <summary>
            Number of tokens from cached content.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIPromptTokensDetails.AudioTokens">
            <summary>
            Number of tokens from audio input.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIPromptTokensDetails.#ctor">
            <summary>
            OpenAI prompt tokens details.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIResponseFormat">
            <summary>
            OpenAI response format specification.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIResponseFormat.Type">
            <summary>
            Type of response format.
            Valid values: "text", "json_object", "json_schema"
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIResponseFormat.JsonSchema">
            <summary>
            JSON schema for structured output (when type is "json_schema").
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIResponseFormat.#ctor">
            <summary>
            OpenAI response format.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIStopInputConverter">
            <summary>
            Converter for flexible stop sequences (string or array).
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult">
            <summary>
            OpenAI streaming chat completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Id">
            <summary>
            Unique identifier for the chat completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Object">
            <summary>
            Object type (always "chat.completion.chunk").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.SystemFingerprint">
            <summary>
            System fingerprint.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Choices">
            <summary>
            List of chat completion choices with deltas.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.Usage">
            <summary>
            Usage statistics (only in final chunk).
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.IsFinalChunk">
            <summary>
            Checks if this is the final chunk.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingChatCompletionResult.#ctor">
            <summary>
            OpenAI streaming chat completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult">
            <summary>
            OpenAI streaming completion result.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.Id">
            <summary>
            Unique identifier for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.Object">
            <summary>
            Object type (always "text_completion").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.Created">
            <summary>
            Unix timestamp when the completion was created.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.Model">
            <summary>
            Model used for the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.Choices">
            <summary>
            List of completion choices.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIStreamingCompletionResult.#ctor">
            <summary>
            OpenAI streaming completion result.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAITool">
            <summary>
            OpenAI tool definition.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAITool.Type">
            <summary>
            Type of tool (currently only "function" is supported).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAITool.Function">
            <summary>
            Function definition.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAITool.#ctor">
            <summary>
            OpenAI tool.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIToolCall">
            <summary>
            OpenAI tool call.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolCall.Id">
            <summary>
            Unique identifier for the tool call.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolCall.Type">
            <summary>
            Type of tool call (currently only "function").
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolCall.Function">
            <summary>
            Function call details.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIToolCall.#ctor">
            <summary>
            OpenAI tool call.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIToolCallFunction">
            <summary>
            OpenAI tool call function details.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolCallFunction.Name">
            <summary>
            Name of the function to call.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolCallFunction.Arguments">
            <summary>
            Arguments to pass to the function as a JSON string.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIToolCallFunction.#ctor">
            <summary>
            OpenAI tool call function.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction">
            <summary>
            OpenAI tool function definition.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction.Name">
            <summary>
            Name of the function.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction.Description">
            <summary>
            Description of what the function does.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction.Parameters">
            <summary>
            Parameters the function accepts, described as a JSON Schema object.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction.Strict">
            <summary>
            Whether to enable strict schema adherence.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIToolFunction.#ctor">
            <summary>
            OpenAI tool function.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAITopLogprob">
            <summary>
            OpenAI top logprob entry.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAITopLogprob.Token">
            <summary>
            The token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAITopLogprob.Logprob">
            <summary>
            Log probability of this token.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAITopLogprob.Bytes">
            <summary>
            UTF-8 byte representation of the token.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAITopLogprob.#ctor">
            <summary>
            OpenAI top logprob.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.OpenAI.OpenAIUsage">
            <summary>
            OpenAI usage statistics.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.PromptTokens">
            <summary>
            Number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.CompletionTokens">
            <summary>
            Number of tokens in the completion.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.TotalTokens">
            <summary>
            Total number of tokens used.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.PromptTokensDetails">
            <summary>
            Detailed breakdown of prompt tokens (for chat completions with images).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.CompletionTokensDetails">
            <summary>
            Detailed breakdown of completion tokens.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.OpenAI.OpenAIUsage.#ctor">
            <summary>
            OpenAI usage.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.RequestContext">
            <summary>
            Request context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.GUID">
            <summary>
            Request GUID.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.RequestType">
            <summary>
            Request type.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.ApiFormat">
            <summary>
            API format.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.ContentType">
            <summary>
            Content-type.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.ContentLength">
            <summary>
            Content length.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.Method">
            <summary>
            HTTP method.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.Url">
            <summary>
            URL.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.UrlContext">
            <summary>
            URL context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.Querystring">
            <summary>
            Querystring.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.Headers">
            <summary>
            Headers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.Query">
            <summary>
            Query.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.HttpContext">
            <summary>
            HTTP context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.IsEmbeddingsRequest">
            <summary>
            Boolean indicating if the request is an embeddings request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.IsCompletionsRequest">
            <summary>
            Boolean indicating if the request is a chat completion request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.RequestContext.ClientIdentifier">
            <summary>
            Client identifier.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.RequestContext.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.RequestContext.#ctor(OllamaFlow.Core.OllamaFlowSettings,WatsonWebserver.Core.HttpContextBase)">
            <summary>
            Instantiate.
            </summary>
            <param name="settings">Settings.</param>
            <param name="ctx">HTTP context.</param>
        </member>
        <member name="T:OllamaFlow.Core.Models.StickySession">
            <summary>
            Represents a sticky session binding a client to a specific backend.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.ClientId">
            <summary>
            Client identifier (typically IP address or value from sticky headers).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.FrontendId">
            <summary>
            Frontend identifier associated with this session.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.BackendId">
            <summary>
            Backend identifier this client is bound to.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.CreatedUtc">
            <summary>
            Creation timestamp, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.ExpiresUtc">
            <summary>
            Expiration timestamp, in UTC time.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.StickySession.LastAccessUtc">
            <summary>
            Last access timestamp, in UTC time.
            Updated each time the session is used.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.StickySession.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.StickySession.#ctor(System.String,System.String,System.String,System.Int32)">
            <summary>
            Instantiate.
            </summary>
            <param name="clientId">Client identifier.</param>
            <param name="frontendId">Frontend identifier.</param>
            <param name="backendId">Backend identifier.</param>
            <param name="expirationMs">Expiration duration in milliseconds.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when required parameters are null or empty.</exception>
            <exception cref="T:System.ArgumentOutOfRangeException">Thrown when expirationMs is less than or equal to zero.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Models.StickySession.IsExpired">
            <summary>
            Check if the session has expired.
            </summary>
            <returns>True if the session has expired, false otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.StickySession.Touch(System.Int32)">
            <summary>
            Update the last access timestamp and extend expiration if needed.
            </summary>
            <param name="expirationMs">New expiration duration in milliseconds.</param>
            <exception cref="T:System.ArgumentOutOfRangeException">Thrown when expirationMs is less than or equal to zero.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Models.StickySession.GetSessionKey">
            <summary>
            Create a unique session key for storage.
            </summary>
            <returns>Session key combining client and frontend identifiers.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Models.TelemetryMessage">
            <summary>
            Telemetry message.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.RequestId">
            <summary>
            Gets or sets the unique identifier for this request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.RequestType">
            <summary>
            Request type.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.ApiFormat">
            <summary>
            API format of the incoming request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.ConversationId">
            <summary>
            Gets or sets the conversation/session identifier this request belongs to.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.BackendServerId">
            <summary>
            Gets or sets the identifier of the backend server that handled this request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.ClientId">
            <summary>
            Gets or sets the identifier of the client that initiated this request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.IsSticky">
            <summary>
            Boolean indicating if the session is sticky.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.TransformationId">
            <summary>
            Gets or sets the transformation identifier if request/response transformation was performed.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.RequestBodySize">
            <summary>
            Request body size in bytes.
            Must be non-negative.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.RequestArrivalUtc">
            <summary>
            Gets or sets the UTC timestamp when the request arrived at the load balancer.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.BackendSelectedUtc">
            <summary>
            Gets or sets the UTC timestamp when a backend server was selected to handle the request.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.BackendRequestSentUtc">
            <summary>
            Gets or sets the UTC timestamp when the request was sent to the backend server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.FirstTokenTimeUtc">
            <summary>
            Gets or sets the UTC timestamp when the first token was received from the backend server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.LastTokenTimeUtc">
            <summary>
            Gets or sets the UTC timestamp when the last token was received from the backend server.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.BackendSelectionTimeMs">
            <summary>
            Gets the time in milliseconds between request arrival and backend server selection.
            Returns null if either timestamp is not set.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.TimeToFirstTokenMs">
            <summary>
            Gets the time in milliseconds between sending the request to backend and receiving the first token.
            Returns null if either timestamp is not set.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.TimeToCompletionMs">
            <summary>
            Gets the time in milliseconds between sending the request to backend and receiving the last token.
            Returns null if either timestamp is not set.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.TelemetryMessage.TotalRequestTimeMs">
            <summary>
            Gets the total end-to-end request time in milliseconds (from arrival to last token).
            Returns null if last token timestamp is not set.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.TelemetryMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:OllamaFlow.Core.Models.TelemetryMessage"/> class.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Models.UrlBuilder">
            <summary>
            URL builder.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlBuilder.BuildUrl(OllamaFlow.Core.OllamaFlowSettings,OllamaFlow.Core.Frontend,OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Build the URL for a given request.
            </summary>
            <param name="settings">Settings.</param>
            <param name="frontend">Frontend.</param>
            <param name="requestType">Request type.</param>
            <returns>URL.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlBuilder.BuildUrl(OllamaFlow.Core.Backend,OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Build the URL for a given request.
            </summary>
            <param name="backend">Backend.</param>
            <param name="requestType">Request type.</param>
            <returns>URL.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlBuilder.GetMethod(OllamaFlow.Core.Backend,OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Get the HTTP method used for a given request type.
            </summary>
            <param name="backend">Backend.</param>
            <param name="requestType">Request type.</param>
            <returns>HTTP method.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlBuilder.GetMethod(OllamaFlow.Core.Enums.ApiFormatEnum,OllamaFlow.Core.Enums.RequestTypeEnum)">
            <summary>
            Get the HTTP method used for a given request type.
            </summary>
            <param name="apiFormat">API format.</param>
            <param name="requestType">Request type.</param>
            <returns>HTTP method.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Models.UrlContext">
            <summary>
            URL context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.Logger">
            <summary>
            Method to invoke to emit log messages.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.RequestType">
            <summary>
            Request type.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.ApiFormat">
            <summary>
            API format.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.HttpMethod">
            <summary>
            HTTP method.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.Query">
            <summary>
            Query.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.Headers">
            <summary>
            Headers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Models.UrlContext.UrlParameters">
            <summary>
            URL parameters.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.#ctor(WatsonWebserver.Core.HttpMethod,System.String,System.Collections.Specialized.NameValueCollection,System.Collections.Specialized.NameValueCollection)">
            <summary>
            Instantiate.
            </summary>
            <param name="method">HTTP method.</param>
            <param name="url">URL.</param>
            <param name="query">Query.</param>
            <param name="headers">Headers.</param>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.ParameterExists(System.String)">
            <summary>
            Check if a parameter exists.
            </summary>
            <param name="key">Key.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.GetParameter(System.String)">
            <summary>
            Retrieve URL parameter.
            </summary>
            <param name="key">Parameter.</param>
            <returns>Value or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.GetQueryValue(System.String)">
            <summary>
            Retrieve query value.
            </summary>
            <param name="key">Key.</param>
            <returns>Value or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.GetHeaderValue(System.String)">
            <summary>
            Retrieve header value.
            </summary>
            <param name="key">Key.</param>
            <returns>Value or null.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.QueryExists(System.String)">
            <summary>
            Check if a query key exists.
            </summary>
            <param name="key">Key.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Models.UrlContext.HeaderExists(System.String)">
            <summary>
            Check if a header exists.
            </summary>
            <param name="key">Key.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="T:OllamaFlow.Core.OllamaFlowCallbacks">
            <summary>
            OllamaFlow callbacks.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.OllamaFlowCallbacks.#ctor">
            <summary>
            OllamaFlow callbacks.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.OllamaFlowDaemon">
            <summary>
            OllamaFlow Daemon.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.Callbacks">
            <summary>
            OllamaFlow callbacks.  Attach handlers to these methods to integrate your application logic into OllamaFlow.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.Backends">
            <summary>
            Backend service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.Frontends">
            <summary>
            Frontend service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.Gateway">
            <summary>
            Gateway service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.HealthCheck">
            <summary>
            Healthcheck service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.ModelSynchronization">
            <summary>
            Model synchronization service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowDaemon.SessionStickiness">
            <summary>
            Session stickiness service.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.OllamaFlowDaemon.#ctor(OllamaFlow.Core.OllamaFlowSettings,System.Threading.CancellationTokenSource)">
            <summary>
            Instantiate.
            </summary>
            <param name="settings">Settings.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.OllamaFlowDaemon.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.OllamaFlowDaemon.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="T:OllamaFlow.Core.OllamaFlowSettings">
            <summary>
            Settings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowSettings.Logging">
            <summary>
            Logging settings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowSettings.Webserver">
            <summary>
            Webserver settings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowSettings.DatabaseFilename">
            <summary>
            Database filename.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowSettings.AdminBearerTokens">
            <summary>
            Administrator bearer tokens.
            </summary> 
        </member>
        <member name="P:OllamaFlow.Core.OllamaFlowSettings.StickyHeaders">
            <summary>
            List of headers to use to identify a node when evaluating session stickiness.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.OllamaFlowSettings.#ctor">
            <summary>
            Instantiate.
            </summary> 
        </member>
        <member name="T:OllamaFlow.Core.Serialization.ISerializer">
            <summary>
            Serializer interface.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.ISerializer.CopyObject``1(``0)">
            <summary>
            Copy an object.
            </summary>
            <typeparam name="T">Type.</typeparam>
            <param name="obj">Object.</param>
            <returns>Copied object.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.ISerializer.SerializeJson(System.Object,System.Boolean)">
            <summary>
            Serialize an object to JSON.
            </summary>
            <param name="obj">Object.</param>
            <param name="pretty">Enable or disable pretty formatting.</param>
            <returns></returns>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.ISerializer.DeserializeJson``1(System.String)">
            <summary>
            Deserialize an object to JSON.
            </summary>
            <typeparam name="T">Type.</typeparam>
            <param name="json">JSON.</param>
            <returns>Instance.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Serialization.Serializer">
            <summary>
            Serialization.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.Serializer.CopyObject``1(``0)">
            <inheritdoc/>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.Serializer.DeserializeJson``1(System.String)">
            <inheritdoc/>
        </member>
        <member name="M:OllamaFlow.Core.Serialization.Serializer.SerializeJson(System.Object,System.Boolean)">
            <inheritdoc/>
        </member>
        <member name="T:OllamaFlow.Core.Services.BackendService">
            <summary>
            Backend service.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Database.DatabaseDriverBase,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Backend service.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging module.</param>
            <param name="database">Database driver.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Create(OllamaFlow.Core.Backend)">
            <summary>
            Create a new backend.
            </summary>
            <param name="backend">Backend to create.</param>
            <returns>Created backend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetByIdentifier(System.String)">
            <summary>
            Get a backend by identifier.
            </summary>
            <param name="identifier">Backend identifier.</param>
            <returns>Backend if found, null otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetByIdentifiers(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Get multiple backends by identifiers.
            </summary>
            <param name="identifiers">Backend identifiers.</param>
            <returns>Backends.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <summary>
            Get all backends.
            </summary>
            <param name="order">Sort order.</param>
            <returns>All backends.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetPage(OllamaFlow.Core.EnumerationRequest)">
            <summary>
            Get a page of backends.
            </summary>
            <param name="request">Enumeration request.</param>
            <returns>Enumeration result.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Update(OllamaFlow.Core.Backend)">
            <summary>
            Update a backend.
            </summary>
            <param name="backend">Backend to update.</param>
            <returns>Updated backend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Delete(System.String,System.Boolean)">
            <summary>
            Delete a backend by identifier.
            </summary>
            <param name="identifier">Backend identifier.</param>
            <param name="force">Force deletion even if linked to frontends.</param>
            <returns>True if deleted, false if linked and not forced.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Exists(System.String)">
            <summary>
            Check if a backend exists.
            </summary>
            <param name="identifier">Backend identifier.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.IsLinked(System.String)">
            <summary>
            Check if a backend is linked to any frontends.
            </summary>
            <param name="identifier">Backend identifier.</param>
            <returns>True if linked.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <summary>
            Get the total count of backends.
            </summary>
            <param name="order">Sort order.</param>
            <param name="continuationToken">Continuation token.</param>
            <returns>Total count.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.GetByFrontendIdentifier(System.String)">
            <summary>
            Get backends for a specific frontend.
            </summary>
            <param name="frontendIdentifier">Frontend identifier.</param>
            <returns>Backends associated with the frontend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.BackendService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Services.FrontendService">
            <summary>
            Frontend service.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Database.DatabaseDriverBase,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Frontend service.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging module.</param>
            <param name="database">Database driver.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Create(OllamaFlow.Core.Frontend)">
            <summary>
            Create a new frontend.
            </summary>
            <param name="frontend">Frontend to create.</param>
            <returns>Created frontend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetByIdentifier(System.String)">
            <summary>
            Get a frontend by identifier.
            </summary>
            <param name="identifier">Frontend identifier.</param>
            <returns>Frontend if found, null otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetByIdentifiers(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Get multiple frontends by identifiers.
            </summary>
            <param name="identifiers">Frontend identifiers.</param>
            <returns>Frontends.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetAll(OllamaFlow.Core.Enums.EnumerationOrderEnum)">
            <summary>
            Get all frontends.
            </summary>
            <param name="order">Sort order.</param>
            <returns>All frontends.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetPage(OllamaFlow.Core.EnumerationRequest)">
            <summary>
            Get a page of frontends.
            </summary>
            <param name="request">Enumeration request.</param>
            <returns>Enumeration result.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Update(OllamaFlow.Core.Frontend)">
            <summary>
            Update a frontend.
            </summary>
            <param name="frontend">Frontend to update.</param>
            <returns>Updated frontend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Delete(System.String)">
            <summary>
            Delete a frontend by identifier.
            </summary>
            <param name="identifier">Frontend identifier.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Exists(System.String)">
            <summary>
            Check if a frontend exists.
            </summary>
            <param name="identifier">Frontend identifier.</param>
            <returns>True if exists.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetCount(OllamaFlow.Core.Enums.EnumerationOrderEnum,System.String)">
            <summary>
            Get the total count of frontends.
            </summary>
            <param name="order">Sort order.</param>
            <param name="continuationToken">Continuation token.</param>
            <returns>Total count.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.GetByBackendIdentifier(System.String)">
            <summary>
            Get frontends by backend identifier.
            </summary>
            <param name="backendIdentifier">Backend identifier.</param>
            <returns>Frontends that reference the backend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.FrontendService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Services.GatewayService">
            <summary>
            Gateway service responsible for coordinating request processing and routing.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.#ctor(OllamaFlow.Core.OllamaFlowSettings,OllamaFlow.Core.OllamaFlowCallbacks,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,OllamaFlow.Core.Services.ServiceContext,OllamaFlow.Core.Handlers.HandlerContext,System.Threading.CancellationTokenSource)">
            <summary>
            Instantiate.
            </summary>
            <param name="settings">Settings.</param>
            <param name="callbacks">Callbacks.</param>
            <param name="logging">Logging.</param>
            <param name="serializer">Serializer.</param>
            <param name="services">Service context.</param>
            <param name="handlers">Handler context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.OptionsRoute(WatsonWebserver.Core.HttpContextBase)">
            <summary>
            OPTIONS route handler for CORS support.
            </summary>
            <param name="ctx">HTTP context.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.PreRoutingHandler(WatsonWebserver.Core.HttpContextBase)">
            <summary>
            Pre-routing handler for request setup.
            </summary>
            <param name="ctx">HTTP context.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.PostRoutingHandler(WatsonWebserver.Core.HttpContextBase)">
            <summary>
            Post-routing handler for cleanup.
            </summary>
            <param name="ctx">HTTP context.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.ExceptionRoute(WatsonWebserver.Core.HttpContextBase,System.Exception,System.Threading.CancellationToken)">
            <summary>
            Exception route handler for unhandled exceptions.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="e">Exception.</param>
            <param name="token">Cancellation token.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.DefaultRoute(WatsonWebserver.Core.HttpContextBase)">
            <summary>
            Default route handler - main entry point for AI API requests.
            </summary>
            <param name="ctx">HTTP context.</param>
            <returns>Task.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.HandleAdminApiRequest(WatsonWebserver.Core.HttpContextBase,OllamaFlow.Core.Models.RequestContext,System.Threading.CancellationToken)">
            <summary>
            Handler for administrative API requests.
            Return true if the request is handled, otherwise, return false.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="req">Request context.</param>
            <param name="token">Cancellation token.</param>
            <returns>True if the request is handled and complete, false otherwise.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.GatewayService.ProcessRequest(WatsonWebserver.Core.HttpContextBase,OllamaFlow.Core.Models.RequestContext,OllamaFlow.Core.Frontend,OllamaFlow.Core.Models.TelemetryMessage,System.Threading.CancellationToken)">
            <summary>
            Process a request.  This method will retrieve the backend, perform transformations as needed, and marshal the request to the backend.
            The return value indicates whether or not the request has been fully serviced to its completion.
            If the result from the backend should be retried, return false.  Examples include 500-series errors or no connectivity to a backend.
            If the result from the backend is complete, return true.  Examples include successful responses and 400-series errors.
            </summary>
            <param name="ctx">HTTP context.</param>
            <param name="req">Request context.</param>
            <param name="frontend">Frontend.</param>
            <param name="telemetry">Telemetry message.</param>
            <param name="token">Cancellation token.</param>
            <returns>True if the request has been serviced to completion.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Services.HealthCheckService">
            <summary>
            Health check service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.HealthCheckService.IntervalMs">
            <summary>
            Interval, in milliseconds.
            Default is 5000.
            Minimum is 1000.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.HealthCheckService.Frontends">
            <summary>
            Retrieve the list of frontends in memory.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.HealthCheckService.Backends">
            <summary>
            Retrieve the list of backends in memory.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Health check service.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging.</param>
            <param name="serializer">Serializer.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.IsHealthy(System.String)">
            <summary>
            Test if a frontend is healthy.
            </summary>
            <param name="identifier">Identifier.</param>
            <returns>True if healthy.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.GetNextBackend(OllamaFlow.Core.Frontend,OllamaFlow.Core.Enums.RequestTypeEnum,System.String)">
            <summary>
            Retrieve the next backend that should be used for a request to a given frontend.
            </summary>
            <param name="frontend">Frontend.</param>
            <param name="requestType">Type of request to filter backends by capability.</param>
            <param name="label">Label on which to match.</param>
            <returns>Backend.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when frontend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.GetNextBackend(OllamaFlow.Core.Models.RequestContext,OllamaFlow.Core.Frontend)">
            <summary>
            Retrieve the next backend that should be used for a request to a given frontend, considering sticky sessions.
            </summary>
            <param name="req">Request context.</param>
            <param name="frontend">Frontend.</param>
            <returns>Backend.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.UpdateBackend(OllamaFlow.Core.Backend)">
            <summary>
            Update a backend if cached.
            </summary>
            <param name="backend">Backend.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when backend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.AddBackend(OllamaFlow.Core.Backend)">
            <summary>
            Add a new backend to health monitoring.
            </summary>
            <param name="backend">Backend to add.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when backend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.RemoveBackend(System.String)">
            <summary>
            Remove a backend from health monitoring.
            </summary>
            <param name="identifier">Backend identifier to remove.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when identifier is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.UpdateFrontend(OllamaFlow.Core.Frontend)">
            <summary>
            Update a frontend if cached.
            </summary>
            <param name="frontend">Frontend to update.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when frontend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.AddFrontend(OllamaFlow.Core.Frontend)">
            <summary>
            Add a new frontend to monitoring.
            </summary>
            <param name="frontend">Frontend to add.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when frontend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.HealthCheckService.RemoveFrontend(System.String)">
            <summary>
            Remove a frontend from monitoring.
            </summary>
            <param name="identifier">Frontend identifier to remove.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when identifier is null.</exception>
        </member>
        <member name="T:OllamaFlow.Core.Services.ModelSynchronizationService">
            <summary>
            Model synchronization service.
            Only operates on Ollama backends since OpenAI/vLLM backends don't support runtime model pulling.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ModelSynchronizationService.IntervalMs">
            <summary>
            Interval, in milliseconds.
            Default is 30000.
            Minimum is 5000.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ModelSynchronizationService.MaxConcurrentDownloadsPerBackend">
            <summary>
            Maximum concurrent downloads per backend.
            Default is 3.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ModelSynchronizationService.ActivePulls">
            <summary>
            Retrieve the current list of active model pulls.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Serialization.Serializer,OllamaFlow.Core.Services.ServiceContext,System.Threading.CancellationTokenSource)">
            <summary>
            Model synchronization service.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging.</param>
            <param name="serializer">Serializer.</param>
            <param name="services">Service context.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.GetBackendModels(System.String)">
            <summary>
            Get discovered models for a specific backend.
            </summary>
            <param name="backendIdentifier">Backend identifier.</param>
            <returns>List of model names, or empty list if backend not found.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when backendIdentifier is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.AddBackend(OllamaFlow.Core.Backend)">
            <summary>
            Add a backend and start model synchronization for it.
            Only operates on Ollama backends since OpenAI/vLLM don't support runtime model pulling.
            </summary>
            <param name="backend">Backend that was added.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when backend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.UpdateBackend(OllamaFlow.Core.Backend)">
            <summary>
            Update a backend configuration.
            </summary>
            <param name="backend">Backend that was updated.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when backend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.RemoveBackend(System.String)">
            <summary>
            Remove a backend and stop model synchronization for it.
            </summary>
            <param name="identifier">Identifier of backend that was removed.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when identifier is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.AddFrontend(OllamaFlow.Core.Frontend)">
            <summary>
            Add a frontend and sync its required models.
            </summary>
            <param name="frontend">Frontend that was added.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when frontend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.UpdateFrontend(OllamaFlow.Core.Frontend)">
            <summary>
            Update a frontend configuration and sync required models.
            </summary>
            <param name="frontend">Frontend that was updated.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when frontend is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.ModelSynchronizationService.RemoveFrontend(System.String)">
            <summary>
            Remove a frontend.
            </summary>
            <param name="identifier">Identifier of frontend that was removed.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when identifier is null.</exception>
        </member>
        <member name="T:OllamaFlow.Core.Services.ServiceContext">
            <summary>
            Service context.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.Backend">
            <summary>
            Backend service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.Frontend">
            <summary>
            Frontend service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.Gateway">
            <summary>
            Gateway service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.HealthCheck">
            <summary>
            Healthcheck service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.ModelSynchronization">
            <summary>
            Model synchronization service.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.ServiceContext.SessionStickiness">
            <summary>
            Session stickiness service.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.#ctor(OllamaFlow.Core.OllamaFlowSettings,SyslogLogging.LoggingModule,OllamaFlow.Core.Database.DatabaseDriverBase,OllamaFlow.Core.Serialization.Serializer,System.Threading.CancellationTokenSource)">
            <summary>
            Service context.
            </summary>
            <param name="settings">Settings.</param>
            <param name="logging">Logging.</param>
            <param name="db">Database.</param>
            <param name="serializer">Serializer.</param>
            <param name="tokenSource">Cancellation token source.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddBackend">
            <summary>
            Add the backend service.
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddFrontend">
            <summary>
            Add the frontend service.
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddHealthCheck">
            <summary>
            
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddModelSynchronization">
            <summary>
            
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddSessionStickiness">
            <summary>
            
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.AddGateway(OllamaFlow.Core.OllamaFlowCallbacks,OllamaFlow.Core.Handlers.HandlerContext)">
            <summary>
            Add the gateway service.
            </summary>
            <param name="callbacks">Callbacks.</param>
            <param name="handlers">Handler context.</param>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.Initialize">
            <summary>
            Initialize services.
            </summary>
            <returns>Service context.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.ServiceContext.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Services.SessionStickinessService">
            <summary>
            Service for managing sticky sessions between clients and backends.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.SessionStickinessService.CleanupIntervalMs">
            <summary>
            Interval in milliseconds for cleaning up expired sessions.
            Default is 300000 milliseconds (5 minutes).
            Minimum is 10000 milliseconds (10 seconds).
            Maximum is 3600000 milliseconds (1 hour).
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.SessionStickinessService.ActiveSessionCount">
            <summary>
            Get the total number of active sessions.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Services.SessionStickinessService.Sessions">
            <summary>
            Retrieve the current mapping of sticky sessions.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.#ctor(SyslogLogging.LoggingModule,System.Threading.CancellationTokenSource)">
            <summary>
            Instantiate.
            </summary>
            <param name="logging">Logging module.</param>
            <param name="tokenSource">Cancellation token source.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when logging is null.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.Dispose(System.Boolean)">
            <summary>
            Dispose.
            </summary>
            <param name="disposing">Disposing.</param>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.Dispose">
            <summary>
            Dispose.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.Initialize">
            <summary>
            Initialize.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.GetStickyBackend(System.String,System.String)">
            <summary>
            Get the sticky backend for a client and frontend combination.
            </summary>
            <param name="clientId">Client identifier.</param>
            <param name="frontendId">Frontend identifier.</param>
            <returns>Backend identifier if a valid sticky session exists, null otherwise.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when clientId or frontendId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.SetStickyBackend(System.String,System.String,System.String,System.Int32)">
            <summary>
            Set a sticky backend for a client and frontend combination.
            </summary>
            <param name="clientId">Client identifier.</param>
            <param name="frontendId">Frontend identifier.</param>
            <param name="backendId">Backend identifier.</param>
            <param name="expirationMs">Session expiration in milliseconds.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when required parameters are null or empty.</exception>
            <exception cref="T:System.ArgumentOutOfRangeException">Thrown when expirationMs is less than or equal to zero.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.TouchSession(System.String,System.String,System.Int32)">
            <summary>
            Update the last access time for an existing session and extend its expiration.
            </summary>
            <param name="clientId">Client identifier.</param>
            <param name="frontendId">Frontend identifier.</param>
            <param name="expirationMs">New session expiration in milliseconds.</param>
            <returns>True if the session was found and updated, false otherwise.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when clientId or frontendId is null or empty.</exception>
            <exception cref="T:System.ArgumentOutOfRangeException">Thrown when expirationMs is less than or equal to zero.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.RemoveSession(System.String,System.String)">
            <summary>
            Remove a specific sticky session.
            </summary>
            <param name="clientId">Client identifier.</param>
            <param name="frontendId">Frontend identifier.</param>
            <returns>True if the session was found and removed, false otherwise.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when clientId or frontendId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.RemoveClientSessions(System.String)">
            <summary>
            Remove all sessions for a specific client.
            </summary>
            <param name="clientId">Client identifier.</param>
            <returns>Number of sessions removed.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when clientId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.RemoveFrontendSessions(System.String)">
            <summary>
            Remove all sessions associated with a specific frontend.
            </summary>
            <param name="frontendId">Frontend identifier.</param>
            <returns>Number of sessions removed.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when frontendId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.RemoveBackendSessions(System.String)">
            <summary>
            Remove all sessions associated with a specific backend.
            </summary>
            <param name="backendId">Backend identifier.</param>
            <returns>Number of sessions removed.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when backendId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.GetAllSessions">
            <summary>
            Get all active sessions.
            </summary>
            <returns>List of all active sticky sessions.</returns>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.GetClientSessions(System.String)">
            <summary>
            Get all sessions for a specific client.
            </summary>
            <param name="clientId">Client identifier.</param>
            <returns>List of sessions for the specified client.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown when clientId is null or empty.</exception>
        </member>
        <member name="M:OllamaFlow.Core.Services.SessionStickinessService.ClearAllSessions">
            <summary>
            Clear all sessions.
            </summary>
            <returns>Number of sessions removed.</returns>
        </member>
        <member name="T:OllamaFlow.Core.Settings.LoggingSettings">
            <summary>
            Logging settings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.Enable">
            <summary>
            Enable or disable logging.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.Servers">
            <summary>
            List of syslog servers.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.LogDirectory">
            <summary>
            Log directory.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.LogFilename">
            <summary>
            Log filename.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.ConsoleLogging">
            <summary>
            Enable or disable console logging.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.EnableColors">
            <summary>
            Enable colors in logging.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.MinimumSeverity">
            <summary>
            Minimum severity.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.LogQueries">
            <summary>
            Enable or disable logging of queries.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.LoggingSettings.LogResults">
            <summary>
            Enable or disable logging of results.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Settings.LoggingSettings.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="T:OllamaFlow.Core.Settings.SyslogServer">
            <summary>
            Syslog server settings.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.SyslogServer.Hostname">
            <summary>
            Hostname.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.SyslogServer.Port">
            <summary>
            Port.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.SyslogServer.RandomizePorts">
            <summary>
            Boolean to indicate whether or not randomized port numbers should be used.
            If false, the value in 'Port' will be used.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.SyslogServer.MinimumPort">
            <summary>
            Minimum port.
            </summary>
        </member>
        <member name="P:OllamaFlow.Core.Settings.SyslogServer.MaximumPort">
            <summary>
            Maximum port.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Settings.SyslogServer.#ctor">
            <summary>
            Instantiate.
            </summary>
        </member>
        <member name="M:OllamaFlow.Core.Settings.SyslogServer.#ctor(System.String,System.Int32)">
            <summary>
            Instantiate.
            </summary>
            <param name="hostname">Hostname.</param>
            <param name="port">Port.</param>
        </member>
        <member name="M:OllamaFlow.Core.Settings.SyslogServer.#ctor(System.String,System.Int32,System.Int32)">
            <summary>
            Instantiate.
            </summary>
            <param name="hostname">Hostname.</param>
            <param name="minPort">Minimum port number.</param>
            <param name="maxPort">Maximum port number.</param>
        </member>
    </members>
</doc>
